


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>TorchRL envs &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Task-specific policy in multi-task environments" href="multi_task.html" />
    <link rel="prev" title="TensorDictModule" href="tensordict_module.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  main (None )
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="torchrl_demo.html">Introduction to TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensordict_tutorial.html">TensorDict</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensordict_module.html">TensorDictModule</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="coding_ddpg.html">Coding DDPG using TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="coding_dqn.html">Coding a pixel-based DQN using TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>TorchRL envs</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/tutorials/torch_envs.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <div class="pytorch-call-to-action-links">
            <div id="tutorial-type">tutorials/torch_envs</div>

            <div id="google-colab-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
              <div class="call-to-action-desktop-view">Run in Google Colab</div>
              <div class="call-to-action-mobile-view">Colab</div>
            </div>
            <div id="download-notebook-link">
              <img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
              <div class="call-to-action-desktop-view">Download Notebook</div>
              <div class="call-to-action-mobile-view">Notebook</div>
            </div>
            <div id="github-view-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
              <div class="call-to-action-desktop-view">View on GitHub</div>
              <div class="call-to-action-mobile-view">GitHub</div>
            </div>
          </div>

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-tutorials-torch-envs-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="torchrl-envs">
<span id="sphx-glr-tutorials-torch-envs-py"></span><h1>TorchRL envs<a class="headerlink" href="#torchrl-envs" title="Permalink to this heading">¶</a></h1>
<p>Environments play a crucial role in RL settings, often somewhat similar to
datasets in supervised and unsupervised settings. The RL community has
become quite familiar with OpenAI gym API which offers a flexible way of
building environments, initializing them and interacting with them. However,
many other libraries exist, and the way one interacts with them can be quite
different from what is expected with <em>gym</em>.</p>
<p>Let us start by describing how TorchRL interacts with gym, which will serve
as an introduction to other frameworks.</p>
<section id="gym-environments">
<h2>Gym environments<a class="headerlink" href="#gym-environments" title="Permalink to this heading">¶</a></h2>
<p>To run this part of the tutorial, you will need to have a recent version of
the gym library installed, as well as the atari suite. You can get this
installed by installing the following packages:</p>
<blockquote>
<div><p>$ pip install gym atari-py ale-py gym[accept-rom-license] pygame</p>
</div></blockquote>
<p>To unify all frameworks, torchrl environments are built inside the
<code class="docutils literal notranslate"><span class="pre">__init__</span></code> method with a private method called <code class="docutils literal notranslate"><span class="pre">_build_env</span></code> that
will pass the arguments and keyword arguments to the root library builder.</p>
<p>With gym, it means that building an environment is as easy as:
sphinx_gallery_start_ignore</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="c1"># sphinx_gallery_end_ignore</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">tensordict</span> <span class="kn">import</span> <span class="n">TensorDict</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.envs.libs.gym</span> <span class="kn">import</span> <span class="n">GymEnv</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The list of available environment can be accessed through this command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">GymEnv</span><span class="o">.</span><span class="n">available_envs</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;ALE/Adventure-ram-v5&#39;, &#39;ALE/Adventure-v5&#39;, &#39;ALE/AirRaid-ram-v5&#39;, &#39;ALE/AirRaid-v5&#39;, &#39;ALE/Alien-ram-v5&#39;, &#39;ALE/Alien-v5&#39;, &#39;ALE/Amidar-ram-v5&#39;, &#39;ALE/Amidar-v5&#39;, &#39;ALE/Assault-ram-v5&#39;, &#39;ALE/Assault-v5&#39;]
</pre></div>
</div>
<section id="env-specs">
<h3>Env Specs<a class="headerlink" href="#env-specs" title="Permalink to this heading">¶</a></h3>
<p>Like other frameworks, TorchRL envs have attributes that indicate what
space is for the observations, action and reward. Because it often happens
that more than one observation is retrieved, we expect the observation spec
to be of type <code class="docutils literal notranslate"><span class="pre">CompositeSpec</span></code>. Reward and action do not have this restriction:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Env observation_spec: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_spec</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Env action_spec: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Env reward_spec: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">reward_spec</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Env observation_spec:
 CompositeSpec(
    observation: BoundedTensorSpec(
         shape=torch.Size([3]), space=ContinuousBox(minimum=tensor([-1., -1., -8.]), maximum=tensor([1., 1., 8.])), device=cpu, dtype=torch.float32, domain=continuous))
Env action_spec:
 BoundedTensorSpec(
     shape=torch.Size([1]), space=ContinuousBox(minimum=tensor([-2.]), maximum=tensor([2.])), device=cpu, dtype=torch.float32, domain=continuous)
Env reward_spec:
 UnboundedContinuousTensorSpec(
     shape=torch.Size([1]), space=None, device=cpu, dtype=torch.float32, domain=continuous)
</pre></div>
</div>
<p>Those spec come with a series of useful tools: one can assert whether a
sample is in the defined space. We can also use some heuristic to project
a sample in the space if it is out of space, and generate random (possibly
uniformly distributed) numbers in that space:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">3</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;action is in bounds?</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">bool</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_spec</span><span class="o">.</span><span class="n">is_in</span><span class="p">(</span><span class="n">action</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;projected action: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_spec</span><span class="o">.</span><span class="n">project</span><span class="p">(</span><span class="n">action</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>action is in bounds?
 False
projected action:
 tensor([2.])
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random action: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_spec</span><span class="o">.</span><span class="n">rand</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>random action:
 tensor([0.2338])
</pre></div>
</div>
<p>Envs are also packed with an <code class="docutils literal notranslate"><span class="pre">env.input_spec</span></code> attribute of type
<code class="docutils literal notranslate"><span class="pre">CompositeSpec</span></code>. In brief, <code class="docutils literal notranslate"><span class="pre">input_spec</span></code> should contain all the specs
of the inputs that are required for an env to exectute a step. For stateful
envs (e.g. gym) this should include the action. With stateless environments
(e.g. Brax) this should also include a representation of the previous state.</p>
</section>
<section id="seeding-resetting-and-steps">
<h3>Seeding, resetting and steps<a class="headerlink" href="#seeding-resetting-and-steps" title="Permalink to this heading">¶</a></h3>
<p>The basic operations on an environment are (1) <code class="docutils literal notranslate"><span class="pre">set_seed</span></code>, (2) <code class="docutils literal notranslate"><span class="pre">reset</span></code>
and (3) <code class="docutils literal notranslate"><span class="pre">step</span></code>.</p>
<p>Let’s see how these methods work with TorchRL:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># make sure that all torch code is also reproductible</span>
<span class="n">env</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tensordict</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<p>We can now execute a step in the environment. Since we don’t have a policy,
we can just generate a random action:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">policy</span><span class="p">(</span><span class="n">tensordict</span><span class="p">):</span>
    <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;action&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_spec</span><span class="o">.</span><span class="n">rand</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">tensordict</span>


<span class="n">policy</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
<span class="n">tensordict_out</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
</pre></div>
</div>
<p>By default, the tensordict returned by <code class="docutils literal notranslate"><span class="pre">step</span></code> is the same as the input…</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="n">tensordict</span>
</pre></div>
</div>
<p>… but with new keys</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensordict</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        next: TensorDict(
            fields={
                observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False)},
            batch_size=torch.Size([]),
            device=cpu,
            is_shared=False),
        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),
        reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<p>What we just did (a random step using <code class="docutils literal notranslate"><span class="pre">action_spec.rand()</span></code>) can also be
done via the simple shortcut.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">env</span><span class="o">.</span><span class="n">rand_step</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        next: TensorDict(
            fields={
                observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False)},
            batch_size=torch.Size([]),
            device=cpu,
            is_shared=False),
        reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<p>The new key <code class="docutils literal notranslate"><span class="pre">(&quot;next&quot;,</span> <span class="pre">&quot;observation&quot;)</span></code> (as all keys under the <code class="docutils literal notranslate"><span class="pre">&quot;next&quot;</span></code>
tensordict) have a special role in TorchRL: they indicate that they come
after the key with the same name but without the prefix.</p>
<p>We provide a function <code class="docutils literal notranslate"><span class="pre">step_mdp</span></code> that executes a step in the tensordict:
it returns a new tensordict updated such that <em>t &lt; -t’</em>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.envs.utils</span> <span class="kn">import</span> <span class="n">step_mdp</span>

<span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;some other key&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">tensordict_tprime</span> <span class="o">=</span> <span class="n">step_mdp</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tensordict_tprime</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="p">(</span>
        <span class="n">tensordict_tprime</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;observation&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;observation&quot;</span><span class="p">))</span>
    <span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),
        some other key: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
tensor(True)
</pre></div>
</div>
<p>We can observe that <code class="docutils literal notranslate"><span class="pre">step_mdp</span></code> has removed all the time-dependent
key-value pairs, but not <code class="docutils literal notranslate"><span class="pre">&quot;some</span> <span class="pre">other</span> <span class="pre">key&quot;</span></code>. Also, the new
observation matches the previous one.</p>
<p>Finally, note that the <code class="docutils literal notranslate"><span class="pre">env.reset</span></code> method also accepts a tensordict to update:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensordict</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">({},</span> <span class="p">[])</span>
<span class="k">assert</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span> <span class="ow">is</span> <span class="n">tensordict</span>
<span class="n">tensordict</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=None,
    is_shared=False)
</pre></div>
</div>
</section>
<section id="rollouts">
<h3>Rollouts<a class="headerlink" href="#rollouts" title="Permalink to this heading">¶</a></h3>
<p>The generic environment class provided by TorchRL allows you to run rollouts
easily for a given number of steps:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensordict_rollout</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tensordict_rollout</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        action: Tensor(shape=torch.Size([20, 1]), device=cpu, dtype=torch.float32, is_shared=False),
        done: Tensor(shape=torch.Size([20, 1]), device=cpu, dtype=torch.bool, is_shared=False),
        next: TensorDict(
            fields={
                observation: Tensor(shape=torch.Size([20, 3]), device=cpu, dtype=torch.float32, is_shared=False)},
            batch_size=torch.Size([20]),
            device=cpu,
            is_shared=False),
        observation: Tensor(shape=torch.Size([20, 3]), device=cpu, dtype=torch.float32, is_shared=False),
        reward: Tensor(shape=torch.Size([20, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([20]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<p>The resulting tensordict has a <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> of <code class="docutils literal notranslate"><span class="pre">[20]</span></code>, which is the
length of the trajectory. We can check that the observation match their
next value:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span>
    <span class="n">tensordict_rollout</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;observation&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="o">==</span> <span class="n">tensordict_rollout</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;observation&quot;</span><span class="p">))[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>tensor(True)
</pre></div>
</div>
</section>
<section id="frame-skip">
<h3><code class="docutils literal notranslate"><span class="pre">frame_skip</span></code><a class="headerlink" href="#frame-skip" title="Permalink to this heading">¶</a></h3>
<p>In some instances, it is useful to use a <code class="docutils literal notranslate"><span class="pre">frame_skip</span></code> argument to use the
same action for several consecutive frames.</p>
<p>The resulting tensordict will contain only the last frame observed in the
sequence, but the rewards will be summed over the number of frames.</p>
<p>If the environment reaches a done state during this process, it’ll stop
and return the result of the truncated chain.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">frame_skip</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
</section>
<section id="rendering">
<h3>Rendering<a class="headerlink" href="#rendering" title="Permalink to this heading">¶</a></h3>
<p>Rendering plays an important role in many RL settings, and this is why the
generic environment class from torchrl provides a <code class="docutils literal notranslate"><span class="pre">from_pixels</span></code> keyword
argument that allows the user to quickly ask for image-based environments:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">from_pixels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensordict</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pixels&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_torch_envs_001.png" srcset="../_images/sphx_glr_torch_envs_001.png" alt="torch envs" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.image.AxesImage object at 0x7f22351213f0&gt;
</pre></div>
</div>
<p>Let’s have a look at what the tensordict contains:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensordict</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([500, 500, 3]), device=cpu, dtype=torch.uint8, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<p>We still have a <code class="docutils literal notranslate"><span class="pre">&quot;state&quot;</span></code> that describes what <code class="docutils literal notranslate"><span class="pre">&quot;observation&quot;</span></code> used to
describe in the previous case (the naming difference comes from the fact that
gym now returns a dictionary and TorchRL gets the names from the dictionary
if it exists, otherwise it names the step output <code class="docutils literal notranslate"><span class="pre">&quot;observation&quot;</span></code>: in a
few words, this is due to inconsistencies in the object type returned by
gym environment step method).</p>
<p>One can also discard this supplementary output by asking for the pixels only:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">from_pixels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pixels_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>Some environments only come in image-based format</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;ALE/Pong-v5&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;from pixels: &quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">from_pixels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;tensordict: &quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">())</span>
<span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>from pixels:  True
tensordict:  TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([210, 160, 3]), device=cpu, dtype=torch.uint8, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
</section>
</section>
<section id="deepmind-control-environments">
<h2>DeepMind Control environments<a class="headerlink" href="#deepmind-control-environments" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt>To run this part of the tutorial, make sure you have installed dm_control:</dt><dd><p>$ pip install dm_control</p>
</dd>
</dl>
<p>We also provide a wrapper for DM Control suite. Again, building an
environment is easy: first let’s look at what environments can be accessed.
The <code class="docutils literal notranslate"><span class="pre">available_envs</span></code> now returns a dict of envs and possible tasks:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.envs.libs.dm_control</span> <span class="kn">import</span> <span class="n">DMControlEnv</span>

<span class="n">DMControlEnv</span><span class="o">.</span><span class="n">available_envs</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;acrobot&#39;: [&#39;swingup&#39;, &#39;swingup_sparse&#39;], &#39;ball_in_cup&#39;: [&#39;catch&#39;], &#39;cartpole&#39;: [&#39;balance&#39;, &#39;balance_sparse&#39;, &#39;swingup&#39;, &#39;swingup_sparse&#39;, &#39;three_poles&#39;, &#39;two_poles&#39;], &#39;cheetah&#39;: [&#39;run&#39;], &#39;finger&#39;: [&#39;spin&#39;, &#39;turn_easy&#39;, &#39;turn_hard&#39;], &#39;fish&#39;: [&#39;upright&#39;, &#39;swim&#39;], &#39;hopper&#39;: [&#39;stand&#39;, &#39;hop&#39;], &#39;humanoid&#39;: [&#39;stand&#39;, &#39;walk&#39;, &#39;run&#39;, &#39;run_pure_state&#39;], &#39;manipulator&#39;: [&#39;bring_ball&#39;, &#39;bring_peg&#39;, &#39;insert_ball&#39;, &#39;insert_peg&#39;], &#39;pendulum&#39;: [&#39;swingup&#39;], &#39;point_mass&#39;: [&#39;easy&#39;, &#39;hard&#39;], &#39;reacher&#39;: [&#39;easy&#39;, &#39;hard&#39;], &#39;swimmer&#39;: [&#39;swimmer6&#39;, &#39;swimmer15&#39;], &#39;walker&#39;: [&#39;stand&#39;, &#39;walk&#39;, &#39;run&#39;], &#39;dog&#39;: [&#39;fetch&#39;, &#39;run&#39;, &#39;stand&#39;, &#39;trot&#39;, &#39;walk&#39;], &#39;humanoid_CMU&#39;: [&#39;run&#39;, &#39;stand&#39;], &#39;lqr&#39;: [&#39;lqr_2_1&#39;, &#39;lqr_6_2&#39;], &#39;quadruped&#39;: [&#39;escape&#39;, &#39;fetch&#39;, &#39;run&#39;, &#39;walk&#39;], &#39;stacker&#39;: [&#39;stack_2&#39;, &#39;stack_4&#39;]}
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">DMControlEnv</span><span class="p">(</span><span class="s2">&quot;acrobot&quot;</span><span class="p">,</span> <span class="s2">&quot;swingup&quot;</span><span class="p">)</span>
<span class="n">tensordict</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;result of reset: &quot;</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>result of reset:  TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        orientations: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float64, is_shared=False),
        velocity: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float64, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<p>Of course we can also use pixel-based environments:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">DMControlEnv</span><span class="p">(</span><span class="s2">&quot;acrobot&quot;</span><span class="p">,</span> <span class="s2">&quot;swingup&quot;</span><span class="p">,</span> <span class="n">from_pixels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pixels_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tensordict</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;result of reset: &quot;</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pixels&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_torch_envs_002.png" srcset="../_images/sphx_glr_torch_envs_002.png" alt="torch envs" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>result of reset:  TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([240, 320, 3]), device=cpu, dtype=torch.uint8, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
</section>
<section id="transforming-envs">
<h2>Transforming envs<a class="headerlink" href="#transforming-envs" title="Permalink to this heading">¶</a></h2>
<p>It is common to pre-process the output of an environment before having it
read by the policy or stored in a buffer.</p>
<dl class="simple">
<dt>In many instances, the RL community has adopted a wrapping scheme of the type</dt><dd><p>$ env_transformed = wrapper1(wrapper2(env))</p>
</dd>
</dl>
<p>to transform environments. This has numerous advantages: it makes accessing
the environment specs obvious (the outer wrapper is the source of truth for
the external world), and it makes it easy to interact with vectorized
environment. However it also makes it hard to access inner environments:
say one wants to remove a wrapper (e.g. <code class="docutils literal notranslate"><span class="pre">wrapper2</span></code>) from the chain,
this operation requires us to collect</p>
<blockquote>
<div><p>$ env0 = env.env.env</p>
<p>$ env_transformed_bis = wrapper1(env0)</p>
</div></blockquote>
<p>TorchRL takes the stance of using sequences of transforms instead, as it is
done in other pytorch domain libraries (e.g. <code class="docutils literal notranslate"><span class="pre">torchvision</span></code>). This
approach is also similar to the way distributions are transformed in
<code class="docutils literal notranslate"><span class="pre">torch.distribution</span></code>, where a <code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> object is
built around a <code class="docutils literal notranslate"><span class="pre">base_dist</span></code> distribution and (a sequence of) <code class="docutils literal notranslate"><span class="pre">transforms</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.envs.transforms</span> <span class="kn">import</span> <span class="n">ToTensorImage</span><span class="p">,</span> <span class="n">TransformedEnv</span>

<span class="c1"># ToTensorImage transforms a numpy-like image into a tensor one,</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">DMControlEnv</span><span class="p">(</span><span class="s2">&quot;acrobot&quot;</span><span class="p">,</span> <span class="s2">&quot;swingup&quot;</span><span class="p">,</span> <span class="n">from_pixels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pixels_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;reset before transform: &quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">())</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">ToTensorImage</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;reset after transform: &quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">())</span>
<span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>reset before transform:  TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([240, 320, 3]), device=cpu, dtype=torch.uint8, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
reset after transform:  TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([3, 240, 320]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<p>To compose transforms, simply use the <code class="docutils literal notranslate"><span class="pre">Compose</span></code> class:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.envs.transforms</span> <span class="kn">import</span> <span class="n">Compose</span><span class="p">,</span> <span class="n">Resize</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">DMControlEnv</span><span class="p">(</span><span class="s2">&quot;acrobot&quot;</span><span class="p">,</span> <span class="s2">&quot;swingup&quot;</span><span class="p">,</span> <span class="n">from_pixels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pixels_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">Compose</span><span class="p">(</span><span class="n">ToTensorImage</span><span class="p">(),</span> <span class="n">Resize</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)))</span>
<span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([3, 32, 32]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<p>Transforms can also be added one at a time:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.envs.transforms</span> <span class="kn">import</span> <span class="n">GrayScale</span>

<span class="n">env</span><span class="o">.</span><span class="n">append_transform</span><span class="p">(</span><span class="n">GrayScale</span><span class="p">())</span>
<span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([1, 32, 32]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<p>As expected, the metadata get updated too:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;original obs spec: &quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">observation_spec</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;current obs spec: &quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_spec</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>original obs spec:  CompositeSpec(
    pixels: UnboundedDiscreteTensorSpec(
         shape=torch.Size([240, 320, 3]), space=ContinuousBox(minimum=tensor([[[0, 0, 0],
             [0, 0, 0],
             [0, 0, 0],
             ...,
             [0, 0, 0],
             [0, 0, 0],
             [0, 0, 0]],

            [[0, 0, 0],
             [0, 0, 0],
             [0, 0, 0],
             ...,
             [0, 0, 0],
             [0, 0, 0],
             [0, 0, 0]],

            [[0, 0, 0],
             [0, 0, 0],
             [0, 0, 0],
             ...,
             [0, 0, 0],
             [0, 0, 0],
             [0, 0, 0]],

            ...,

            [[0, 0, 0],
             [0, 0, 0],
             [0, 0, 0],
             ...,
             [0, 0, 0],
             [0, 0, 0],
             [0, 0, 0]],

            [[0, 0, 0],
             [0, 0, 0],
             [0, 0, 0],
             ...,
             [0, 0, 0],
             [0, 0, 0],
             [0, 0, 0]],

            [[0, 0, 0],
             [0, 0, 0],
             [0, 0, 0],
             ...,
             [0, 0, 0],
             [0, 0, 0],
             [0, 0, 0]]]), maximum=tensor([[[255, 255, 255],
             [255, 255, 255],
             [255, 255, 255],
             ...,
             [255, 255, 255],
             [255, 255, 255],
             [255, 255, 255]],

            [[255, 255, 255],
             [255, 255, 255],
             [255, 255, 255],
             ...,
             [255, 255, 255],
             [255, 255, 255],
             [255, 255, 255]],

            [[255, 255, 255],
             [255, 255, 255],
             [255, 255, 255],
             ...,
             [255, 255, 255],
             [255, 255, 255],
             [255, 255, 255]],

            ...,

            [[255, 255, 255],
             [255, 255, 255],
             [255, 255, 255],
             ...,
             [255, 255, 255],
             [255, 255, 255],
             [255, 255, 255]],

            [[255, 255, 255],
             [255, 255, 255],
             [255, 255, 255],
             ...,
             [255, 255, 255],
             [255, 255, 255],
             [255, 255, 255]],

            [[255, 255, 255],
             [255, 255, 255],
             [255, 255, 255],
             ...,
             [255, 255, 255],
             [255, 255, 255],
             [255, 255, 255]]])), device=cpu, dtype=torch.uint8, domain=continuous))
current obs spec:  CompositeSpec(
    pixels: UnboundedDiscreteTensorSpec(
         shape=torch.Size([1, 32, 32]), space=ContinuousBox(minimum=tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
             [0., 0., 0.,  ..., 0., 0., 0.],
             [0., 0., 0.,  ..., 0., 0., 0.],
             ...,
             [0., 0., 0.,  ..., 0., 0., 0.],
             [0., 0., 0.,  ..., 0., 0., 0.],
             [0., 0., 0.,  ..., 0., 0., 0.]]]), maximum=tensor([[[0.9999, 0.9999, 0.9999,  ..., 0.9999, 0.9999, 0.9999],
             [0.9999, 0.9999, 0.9999,  ..., 0.9999, 0.9999, 0.9999],
             [0.9999, 0.9999, 0.9999,  ..., 0.9999, 0.9999, 0.9999],
             ...,
             [0.9999, 0.9999, 0.9999,  ..., 0.9999, 0.9999, 0.9999],
             [0.9999, 0.9999, 0.9999,  ..., 0.9999, 0.9999, 0.9999],
             [0.9999, 0.9999, 0.9999,  ..., 0.9999, 0.9999, 0.9999]]])), device=cpu, dtype=torch.float32, domain=continuous))
</pre></div>
</div>
<p>We can also concatenate tensors if needed:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.envs.transforms</span> <span class="kn">import</span> <span class="n">CatTensors</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">DMControlEnv</span><span class="p">(</span><span class="s2">&quot;acrobot&quot;</span><span class="p">,</span> <span class="s2">&quot;swingup&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;keys before concat: &quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">())</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span>
    <span class="n">env</span><span class="p">,</span>
    <span class="n">CatTensors</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;orientations&quot;</span><span class="p">,</span> <span class="s2">&quot;velocity&quot;</span><span class="p">],</span> <span class="n">out_key</span><span class="o">=</span><span class="s2">&quot;observation&quot;</span><span class="p">),</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;keys after concat: &quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>keys before concat:  TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        orientations: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float64, is_shared=False),
        velocity: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float64, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
keys after concat:  TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        observation: Tensor(shape=torch.Size([6]), device=cpu, dtype=torch.float64, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<p>This feature makes it easy to mofidy the sets of transforms applied to an
environment input and output. In fact, transforms are run both before and
after a step is executed: for the pre-step pass, the <code class="docutils literal notranslate"><span class="pre">in_keys_inv</span></code> list of
keys will be passed to the <code class="docutils literal notranslate"><span class="pre">_inv_apply_transform</span></code> method. An example of
such a transform would be to transform floating-point actions (output from
a neural network) to the double dtype (requires by the wrapped environment).
After the step is executed, the <code class="docutils literal notranslate"><span class="pre">_apply_transform</span></code> method will be
executed on the keys indicated by the <code class="docutils literal notranslate"><span class="pre">in_keys</span></code> list of keys.</p>
<p>Another interesting feature of the environment transforms is that they
allow the user to retrieve the equivalent of <code class="docutils literal notranslate"><span class="pre">env.env</span></code> in the wrapped
case, or in other words the parent environment. The parent environment can
be retrieved by calling <code class="docutils literal notranslate"><span class="pre">transform.parent</span></code>: the returned environment
will consist in a <code class="docutils literal notranslate"><span class="pre">TransformedEnvironment</span></code> with all the transforms up to
(but not including) the current transform. This is be used for instance in
the <code class="docutils literal notranslate"><span class="pre">NoopResetEnv</span></code> case, which when reset executes the following steps:
resets the parent environment before executing a certain number of steps
at random in that environment.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">DMControlEnv</span><span class="p">(</span><span class="s2">&quot;acrobot&quot;</span><span class="p">,</span> <span class="s2">&quot;swingup&quot;</span><span class="p">)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">append_transform</span><span class="p">(</span>
    <span class="n">CatTensors</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;orientations&quot;</span><span class="p">,</span> <span class="s2">&quot;velocity&quot;</span><span class="p">],</span> <span class="n">out_key</span><span class="o">=</span><span class="s2">&quot;observation&quot;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">append_transform</span><span class="p">(</span><span class="n">GrayScale</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;env: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GrayScale transform parent env: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">transform</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">parent</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CatTensors transform parent env: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">transform</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">parent</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>env:
 TransformedEnv(
    env=DMControlEnv(env=acrobot, task=swingup, batch_size=torch.Size([])),
    transform=Compose(
            CatTensors(in_keys=[&#39;orientations&#39;, &#39;velocity&#39;], out_key=observation),
            GrayScale(keys=[&#39;pixels&#39;])))
GrayScale transform parent env:
 TransformedEnv(
    env=DMControlEnv(env=acrobot, task=swingup, batch_size=torch.Size([])),
    transform=Compose(
            CatTensors(in_keys=[&#39;orientations&#39;, &#39;velocity&#39;], out_key=observation)))
CatTensors transform parent env:
 TransformedEnv(
    env=DMControlEnv(env=acrobot, task=swingup, batch_size=torch.Size([])),
    transform=Compose(
    ))
</pre></div>
</div>
</section>
<section id="environment-device">
<h2>Environment device<a class="headerlink" href="#environment-device" title="Permalink to this heading">¶</a></h2>
<p>Transforms can work on device, which can bring a significant speedup when
operations are moderetely or highly computationally demanding. These include
<code class="docutils literal notranslate"><span class="pre">ToTensorImage</span></code>, <code class="docutils literal notranslate"><span class="pre">Resize</span></code>, <code class="docutils literal notranslate"><span class="pre">GrayScale</span></code> etc.</p>
<p>One could legitimately ask what that implies on the wrapped environment
side. Very little for regular environments: the operations will still happen
on the device where they’re supposed to happen. The environment device
attribute in torchrl indicates on which device is the incoming data supposed
to be and on which device the output data will be. Casting from and to that
device is the responsibility of the torchrl environment class. The big
advantage of storing data on GPU is (1) speedup of transforms as mentioned
above and (2) sharing data amongst workers in multiprocessing settings.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.envs.transforms</span> <span class="kn">import</span> <span class="n">CatTensors</span><span class="p">,</span> <span class="n">GrayScale</span><span class="p">,</span> <span class="n">TransformedEnv</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">DMControlEnv</span><span class="p">(</span><span class="s2">&quot;acrobot&quot;</span><span class="p">,</span> <span class="s2">&quot;swingup&quot;</span><span class="p">)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">append_transform</span><span class="p">(</span>
    <span class="n">CatTensors</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;orientations&quot;</span><span class="p">,</span> <span class="s2">&quot;velocity&quot;</span><span class="p">],</span> <span class="n">out_key</span><span class="o">=</span><span class="s2">&quot;observation&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">has_cuda</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">():</span>
    <span class="n">env</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
    <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="running-environments-in-parallel">
<h2>Running environments in parallel<a class="headerlink" href="#running-environments-in-parallel" title="Permalink to this heading">¶</a></h2>
<p>TorchRL provides utilities to run environment in parallel. It is expected
that the various environment read and return tensors of similar shapes and
dtypes (but one could design masking functions to make this possible in case
those tensors differ in shapes). Creating such environments is quite easy.
Let us look at the simplest case:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.envs</span> <span class="kn">import</span> <span class="n">ParallelEnv</span>


<span class="k">def</span> <span class="nf">env_make</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>


<span class="n">parallel_env</span> <span class="o">=</span> <span class="n">ParallelEnv</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">env_make</span><span class="p">)</span>  <span class="c1"># -&gt; creates 3 envs in parallel</span>
<span class="n">parallel_env</span> <span class="o">=</span> <span class="n">ParallelEnv</span><span class="p">(</span>
    <span class="mi">3</span><span class="p">,</span> <span class="p">[</span><span class="n">env_make</span><span class="p">,</span> <span class="n">env_make</span><span class="p">,</span> <span class="n">env_make</span><span class="p">]</span>
<span class="p">)</span>  <span class="c1"># similar to the previous command</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">SerialEnv</span></code> class is similar to the <code class="docutils literal notranslate"><span class="pre">ParallelEnv</span></code> except for the
fact that environments are run sequentially. This is mostly useful for
debugging purposes.</p>
<p><code class="docutils literal notranslate"><span class="pre">ParallelEnv</span></code> instances are created in lazy mode: the environment will
start running only when called. This allows us to move <code class="docutils literal notranslate"><span class="pre">ParallelEnv</span></code>
objects from process to process without worring too much about running
processes. A <code class="docutils literal notranslate"><span class="pre">ParallelEnv</span></code> can be started by calling <code class="docutils literal notranslate"><span class="pre">start</span></code>, <code class="docutils literal notranslate"><span class="pre">reset</span></code>
or simply by calling <code class="docutils literal notranslate"><span class="pre">step</span></code> (if <code class="docutils literal notranslate"><span class="pre">reset</span></code> does not need to be called first).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">parallel_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>LazyStackedTensorDict(
    fields={
        done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),
        observation: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([3]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<p>One can check that the parallel environment has the right batch size.
Conventionally, the first part of the <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> indicates the batch,
the second the time frame. Let’s check that with the <code class="docutils literal notranslate"><span class="pre">rollout</span></code> method:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">parallel_env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        action: Tensor(shape=torch.Size([3, 20, 1]), device=cpu, dtype=torch.float32, is_shared=False),
        done: Tensor(shape=torch.Size([3, 20, 1]), device=cpu, dtype=torch.bool, is_shared=False),
        next: TensorDict(
            fields={
                observation: Tensor(shape=torch.Size([3, 20, 3]), device=cpu, dtype=torch.float32, is_shared=False)},
            batch_size=torch.Size([3, 20]),
            device=cpu,
            is_shared=False),
        observation: Tensor(shape=torch.Size([3, 20, 3]), device=cpu, dtype=torch.float32, is_shared=False),
        reward: Tensor(shape=torch.Size([3, 20, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([3, 20]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<section id="closing-parallel-environments">
<h3>Closing parallel environments<a class="headerlink" href="#closing-parallel-environments" title="Permalink to this heading">¶</a></h3>
<p><strong>Important</strong>: before closing a program, it is important to close the
parallel environment. In general, even with regular environments, it is good
practice to close a function with a call to <code class="docutils literal notranslate"><span class="pre">close</span></code>. In some instances,
TorchRL will throw an error if this is not done (and often it will be at the
end of a program, when the environment gets out of scope!)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">parallel_env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="seeding">
<h3>Seeding<a class="headerlink" href="#seeding" title="Permalink to this heading">¶</a></h3>
<p>When seeding a parallel environment, the difficulty we face is that we don’t
want to provide the same seed to all environments. The heuristic used by
TorchRL is that we produce a deterministic chain of seeds given the input
seed in a - so to say - Markovian way, such that it can be reconstructed
from any of its elements. All <code class="docutils literal notranslate"><span class="pre">set_seed</span></code> methods will return the next seed to
be used, such that one can easily keep the chain going given the last seed.
This is useful when several collectors all contain a <code class="docutils literal notranslate"><span class="pre">ParallelEnv</span></code>
instance and we want each of the sub-sub-environments to have a different seed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">out_seed</span> <span class="o">=</span> <span class="n">parallel_env</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out_seed</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>3288080526
</pre></div>
</div>
</section>
<section id="accessing-environment-attributes">
<h3>Accessing environment attributes<a class="headerlink" href="#accessing-environment-attributes" title="Permalink to this heading">¶</a></h3>
<p>It sometimes occurs that a wrapped environment has an attribute that is of
interest. First, note that TorchRL environment wrapper constains the toolings
to access this attribute. Here’s an example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">sleep</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">uuid</span> <span class="kn">import</span> <span class="n">uuid1</span>


<span class="k">def</span> <span class="nf">env_make</span><span class="p">():</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>
    <span class="n">env</span><span class="o">.</span><span class="n">_env</span><span class="o">.</span><span class="n">foo</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;bar_</span><span class="si">{</span><span class="n">uuid1</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">env</span><span class="o">.</span><span class="n">_env</span><span class="o">.</span><span class="n">get_something</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">r</span><span class="p">:</span> <span class="n">r</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">env</span>


<span class="n">env</span> <span class="o">=</span> <span class="n">env_make</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Goes through env._env</span>
<span class="n">env</span><span class="o">.</span><span class="n">foo</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&#39;bar_06262698-98b0-11ed-afa4-0242ac120002&#39;
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">parallel_env</span> <span class="o">=</span> <span class="n">ParallelEnv</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">env_make</span><span class="p">)</span>  <span class="c1"># -&gt; creates 3 envs in parallel</span>

<span class="c1"># env has not been started --&gt; error:</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">parallel_env</span><span class="o">.</span><span class="n">foo</span>
<span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Aargh what did I do!&quot;</span><span class="p">)</span>
    <span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># make sure we don&#39;t get ahead of ourselves</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Aargh what did I do!
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">parallel_env</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="n">foo_list</span> <span class="o">=</span> <span class="n">parallel_env</span><span class="o">.</span><span class="n">foo</span>
<span class="n">foo_list</span>  <span class="c1"># needs to be instantiated, for instance using list</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;torchrl.envs.vec_env._dispatch_caller_parallel object at 0x7f221e839d20&gt;
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">foo_list</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;bar_09340e2c-98b0-11ed-b19f-0242ac120002&#39;, &#39;bar_095304b2-98b0-11ed-b0f8-0242ac120002&#39;, &#39;bar_095fcc42-98b0-11ed-83d8-0242ac120002&#39;]
</pre></div>
</div>
<p>Similarly, methods can also be accessed:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">something</span> <span class="o">=</span> <span class="n">parallel_env</span><span class="o">.</span><span class="n">get_something</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[1, 1, 1]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">parallel_env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="kwargs-for-parallel-environments">
<h3>kwargs for parallel environments<a class="headerlink" href="#kwargs-for-parallel-environments" title="Permalink to this heading">¶</a></h3>
<p>One may want to provide kwargs to the various environments. This can achieved
either at construction time or afterwards:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.envs</span> <span class="kn">import</span> <span class="n">Compose</span><span class="p">,</span> <span class="n">ParallelEnv</span><span class="p">,</span> <span class="n">Resize</span><span class="p">,</span> <span class="n">ToTensorImage</span><span class="p">,</span> <span class="n">TransformedEnv</span>
<span class="kn">from</span> <span class="nn">torchrl.envs.libs.gym</span> <span class="kn">import</span> <span class="n">GymEnv</span>


<span class="k">def</span> <span class="nf">env_make</span><span class="p">(</span><span class="n">env_name</span><span class="p">):</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span>
        <span class="n">GymEnv</span><span class="p">(</span><span class="n">env_name</span><span class="p">,</span> <span class="n">from_pixels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pixels_only</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">Compose</span><span class="p">(</span><span class="n">ToTensorImage</span><span class="p">(),</span> <span class="n">Resize</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">env</span>


<span class="n">parallel_env</span> <span class="o">=</span> <span class="n">ParallelEnv</span><span class="p">(</span>
    <span class="mi">2</span><span class="p">,</span>
    <span class="p">[</span><span class="n">env_make</span><span class="p">,</span> <span class="n">env_make</span><span class="p">],</span>
    <span class="p">[{</span><span class="s2">&quot;env_name&quot;</span><span class="p">:</span> <span class="s2">&quot;ALE/AirRaid-v5&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;env_name&quot;</span><span class="p">:</span> <span class="s2">&quot;ALE/Pong-v5&quot;</span><span class="p">}],</span>
<span class="p">)</span>
<span class="n">tensordict</span> <span class="o">=</span> <span class="n">parallel_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tensordict</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pixels&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tensordict</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pixels&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">parallel_env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_torch_envs_003.png" srcset="../_images/sphx_glr_torch_envs_003.png" alt="torch envs" class = "sphx-glr-single-img"/></section>
</section>
<section id="transforming-parallel-environments">
<h2>Transforming parallel environments<a class="headerlink" href="#transforming-parallel-environments" title="Permalink to this heading">¶</a></h2>
<p>There are two equivalent ways of transforming parallen environments: in each
process separately, or on the main process. It is even possible to do both.
One can therefore think carefully about the transform design to leverage the
device capabilities (e.g. transforms on cuda devices) and vectorizing
operations on the main process if possible.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.envs</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Compose</span><span class="p">,</span>
    <span class="n">GrayScale</span><span class="p">,</span>
    <span class="n">ParallelEnv</span><span class="p">,</span>
    <span class="n">Resize</span><span class="p">,</span>
    <span class="n">ToTensorImage</span><span class="p">,</span>
    <span class="n">TransformedEnv</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">torchrl.envs.libs.gym</span> <span class="kn">import</span> <span class="n">GymEnv</span>


<span class="k">def</span> <span class="nf">env_make</span><span class="p">(</span><span class="n">env_name</span><span class="p">):</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span>
        <span class="n">GymEnv</span><span class="p">(</span><span class="n">env_name</span><span class="p">,</span> <span class="n">from_pixels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pixels_only</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">Compose</span><span class="p">(</span><span class="n">ToTensorImage</span><span class="p">(),</span> <span class="n">Resize</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)),</span>
    <span class="p">)</span>  <span class="c1"># transforms on remote processes</span>
    <span class="k">return</span> <span class="n">env</span>


<span class="n">parallel_env</span> <span class="o">=</span> <span class="n">ParallelEnv</span><span class="p">(</span>
    <span class="mi">2</span><span class="p">,</span>
    <span class="p">[</span><span class="n">env_make</span><span class="p">,</span> <span class="n">env_make</span><span class="p">],</span>
    <span class="p">[{</span><span class="s2">&quot;env_name&quot;</span><span class="p">:</span> <span class="s2">&quot;ALE/AirRaid-v5&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;env_name&quot;</span><span class="p">:</span> <span class="s2">&quot;ALE/Pong-v5&quot;</span><span class="p">}],</span>
<span class="p">)</span>
<span class="n">parallel_env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span><span class="n">parallel_env</span><span class="p">,</span> <span class="n">GrayScale</span><span class="p">())</span>  <span class="c1"># transforms on main process</span>
<span class="n">tensordict</span> <span class="o">=</span> <span class="n">parallel_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;grayscale tensordict: &quot;</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tensordict</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pixels&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tensordict</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pixels&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">parallel_env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_torch_envs_004.png" srcset="../_images/sphx_glr_torch_envs_004.png" alt="torch envs" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>grayscale tensordict:  LazyStackedTensorDict(
    fields={
        done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([2, 1, 64, 64]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([2]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
</section>
<section id="vecnorm">
<h2>VecNorm<a class="headerlink" href="#vecnorm" title="Permalink to this heading">¶</a></h2>
<p>In RL, we commonly face the problem of normalizing data before inputting
them into a model. Sometimes, we can get a good approximation of the
normalizing statistics from data gathered in the environment with, say, a
random policy (or demonstrations). It might, however, be advisable to
normalize the data “on-the-fly”, updating the normalizing constants
progressively to what has been observed so far. This is particularily
useful when we expect the normalizing statistics to change following
changes in performance in the task, or when the environment is evolving
due to external factors.</p>
<p><strong>Caution</strong>: this feature should be used with caution with off-policy
learning, as old data will be “deprecated” due to its normalization with
previously valid normalizing statistics. In on-policy settings too, this
feature makes learning non-steady and may have unexpected effects. One
would therefore advice users to rely on this feature with caution and compare
it with data normalizing given a fixed version of the normalizing constants.</p>
<p>In regular setting, using VecNorm is quite easy:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.envs.libs.gym</span> <span class="kn">import</span> <span class="n">GymEnv</span>
<span class="kn">from</span> <span class="nn">torchrl.envs.transforms</span> <span class="kn">import</span> <span class="n">TransformedEnv</span><span class="p">,</span> <span class="n">VecNorm</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span><span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">),</span> <span class="n">VecNorm</span><span class="p">())</span>
<span class="n">tensordict</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mean: :&quot;</span><span class="p">,</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;observation&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>  <span class="c1"># Approx 0</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;std: :&quot;</span><span class="p">,</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;observation&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>  <span class="c1"># Approx 1</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>mean: : tensor([-0.1812,  0.4036,  0.1369])
std: : tensor([1.0397, 1.0930, 1.1603])
</pre></div>
</div>
<p>In <strong>parallel envs</strong> things are slightly more complicated, as we need to
share the running statistics amongst the processes. We created a class
<code class="docutils literal notranslate"><span class="pre">EnvCreator</span></code> that is responsible for looking at an environment creation
method, retrieving tensordicts to share amongst processes in the environment
class, and pointing each process to the right common, shared tensordict
once created:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.envs</span> <span class="kn">import</span> <span class="n">EnvCreator</span><span class="p">,</span> <span class="n">ParallelEnv</span>
<span class="kn">from</span> <span class="nn">torchrl.envs.libs.gym</span> <span class="kn">import</span> <span class="n">GymEnv</span>
<span class="kn">from</span> <span class="nn">torchrl.envs.transforms</span> <span class="kn">import</span> <span class="n">TransformedEnv</span><span class="p">,</span> <span class="n">VecNorm</span>

<span class="n">make_env</span> <span class="o">=</span> <span class="n">EnvCreator</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">TransformedEnv</span><span class="p">(</span><span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">),</span> <span class="n">VecNorm</span><span class="p">(</span><span class="n">decay</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)))</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">ParallelEnv</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">make_env</span><span class="p">)</span>
<span class="n">make_env</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="s2">&quot;_extra_state&quot;</span><span class="p">][</span><span class="s2">&quot;td&quot;</span><span class="p">][</span><span class="s2">&quot;observation_count&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">make_env</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="s2">&quot;_extra_state&quot;</span><span class="p">][</span><span class="s2">&quot;td&quot;</span><span class="p">][</span><span class="s2">&quot;observation_ssq&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">make_env</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="s2">&quot;_extra_state&quot;</span><span class="p">][</span><span class="s2">&quot;td&quot;</span><span class="p">][</span><span class="s2">&quot;observation_sum&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>

<span class="n">tensordict</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;tensordict: &quot;</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mean: :&quot;</span><span class="p">,</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;observation&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>  <span class="c1"># Approx 0</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;std: :&quot;</span><span class="p">,</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;observation&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>  <span class="c1"># Approx 1</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>tensordict:  TensorDict(
    fields={
        action: Tensor(shape=torch.Size([3, 5, 2]), device=cpu, dtype=torch.int64, is_shared=False),
        done: Tensor(shape=torch.Size([3, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),
        next: TensorDict(
            fields={
                observation: Tensor(shape=torch.Size([3, 5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},
            batch_size=torch.Size([3, 5]),
            device=cpu,
            is_shared=False),
        observation: Tensor(shape=torch.Size([3, 5, 4]), device=cpu, dtype=torch.float32, is_shared=False),
        reward: Tensor(shape=torch.Size([3, 5, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([3, 5]),
    device=cpu,
    is_shared=False)
mean: : tensor([ 0.1621, -0.1346, -0.2169])
std: : tensor([1.1846, 1.1632, 1.1958])
</pre></div>
</div>
<p>The count is slightly higher than the number of steps (since we
did not use any decay). The difference between the two is due to the fact
that <code class="docutils literal notranslate"><span class="pre">ParallelEnv</span></code> creates a dummy environment to initialize the shared
<code class="docutils literal notranslate"><span class="pre">TensorDict</span></code> that is used to collect data from the dispached environments.
This small difference will usually be absored throughout training.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;update counts: &quot;</span><span class="p">,</span>
    <span class="n">make_env</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="s2">&quot;_extra_state&quot;</span><span class="p">][</span><span class="s2">&quot;td&quot;</span><span class="p">][</span><span class="s2">&quot;observation_count&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>update counts:  tensor([18.])
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  25.446 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-torch-envs-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/b4027b1e6f187fa5875852cc5731ee46/torch_envs.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">torch_envs.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/38053b1c795afb276a1212a585052563/torch_envs.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">torch_envs.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="multi_task.html" class="btn btn-neutral float-right" title="Task-specific policy in multi-task environments" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="tensordict_module.html" class="btn btn-neutral" title="TensorDictModule" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">TorchRL envs</a><ul>
<li><a class="reference internal" href="#gym-environments">Gym environments</a><ul>
<li><a class="reference internal" href="#env-specs">Env Specs</a></li>
<li><a class="reference internal" href="#seeding-resetting-and-steps">Seeding, resetting and steps</a></li>
<li><a class="reference internal" href="#rollouts">Rollouts</a></li>
<li><a class="reference internal" href="#frame-skip"><code class="docutils literal notranslate"><span class="pre">frame_skip</span></code></a></li>
<li><a class="reference internal" href="#rendering">Rendering</a></li>
</ul>
</li>
<li><a class="reference internal" href="#deepmind-control-environments">DeepMind Control environments</a></li>
<li><a class="reference internal" href="#transforming-envs">Transforming envs</a></li>
<li><a class="reference internal" href="#environment-device">Environment device</a></li>
<li><a class="reference internal" href="#running-environments-in-parallel">Running environments in parallel</a><ul>
<li><a class="reference internal" href="#closing-parallel-environments">Closing parallel environments</a></li>
<li><a class="reference internal" href="#seeding">Seeding</a></li>
<li><a class="reference internal" href="#accessing-environment-attributes">Accessing environment attributes</a></li>
<li><a class="reference internal" href="#kwargs-for-parallel-environments">kwargs for parallel environments</a></li>
</ul>
</li>
<li><a class="reference internal" href="#transforming-parallel-environments">Transforming parallel environments</a></li>
<li><a class="reference internal" href="#vecnorm">VecNorm</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/sphinx_highlight.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>

        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>