


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Coding a pixel-based DQN using TorchRL &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="API Reference" href="../reference/index.html" />
    <link rel="prev" title="Coding DDPG using TorchRL" href="coding_ddpg.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  main (None )
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="torchrl_demo.html">Introduction to TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensordict_tutorial.html">TensorDict</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensordict_module.html">TensorDictModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="coding_ddpg.html">Coding DDPG using TorchRL</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Coding a pixel-based DQN using TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Coding a pixel-based DQN using TorchRL</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/tutorials/coding_dqn.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <div class="pytorch-call-to-action-links">
            <div id="tutorial-type">tutorials/coding_dqn</div>

            <div id="google-colab-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
              <div class="call-to-action-desktop-view">Run in Google Colab</div>
              <div class="call-to-action-mobile-view">Colab</div>
            </div>
            <div id="download-notebook-link">
              <img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
              <div class="call-to-action-desktop-view">Download Notebook</div>
              <div class="call-to-action-mobile-view">Notebook</div>
            </div>
            <div id="github-view-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
              <div class="call-to-action-desktop-view">View on GitHub</div>
              <div class="call-to-action-mobile-view">GitHub</div>
            </div>
          </div>

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-tutorials-coding-dqn-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="coding-a-pixel-based-dqn-using-torchrl">
<span id="sphx-glr-tutorials-coding-dqn-py"></span><h1>Coding a pixel-based DQN using TorchRL<a class="headerlink" href="#coding-a-pixel-based-dqn-using-torchrl" title="Permalink to this heading">¶</a></h1>
<p>This tutorial will guide you through the steps to code DQN to solve the
CartPole task from scratch. DQN
(<a class="reference external" href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf">Deep Q-Learning</a>) was
the founding work in deep reinforcement learning. On a high level, the
algorithm is quite simple: Q-learning consists in learning a table of
state-action values in such a way that, when facing any particular state,
we know which action to pick just by searching for the action with the
highest value. This simple setting requires the actions and states to be
discretizable. DQN uses a neural network that maps state-actions pairs to
a certain value, which amortizes the cost of storing and exploring all the
possible states: if a state has not been seen in the past, we can still pass
it through our neural network and get an interpolated value for each of the
actions available.</p>
<p>In this tutorial, you will learn:</p>
<ul class="simple">
<li><p>how to build an environment in TorchRL, including transforms (e.g. data
normalization, frame concatenation, resizing and turning to grayscale)
and parallel execution;</p></li>
<li><p>how to design a QValue actor, i.e. an actor that esitmates the action
values and picks up the action with the highest estimated return;</p></li>
<li><p>how to collect data from your environment efficiently and store them
in a replay buffer;</p></li>
<li><p>how to store trajectories (and not transitions) in your replay buffer),
and how to estimate returns using TD(lambda);</p></li>
<li><p>how to make a module functional and use ;</p></li>
<li><p>and finally how to evaluate your model.</p></li>
</ul>
<p>This tutorial assumes the reader is familiar with some of TorchRL
primitives, such as <code class="docutils literal notranslate"><span class="pre">TensorDict</span></code> and <code class="docutils literal notranslate"><span class="pre">TensorDictModules</span></code>, although it
should be sufficiently transparent to be understood without a deep
understanding of these classes.</p>
<p>We do not aim at giving a SOTA implementation of the algorithm, but rather
to provide a high-level illustration of TorchRL features in the context
of this algorithm.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">tqdm</span>
<span class="kn">from</span> <span class="nn">functorch</span> <span class="kn">import</span> <span class="n">vmap</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">tensordict</span> <span class="kn">import</span> <span class="n">TensorDict</span>
<span class="kn">from</span> <span class="nn">tensordict.nn</span> <span class="kn">import</span> <span class="n">get_functional</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torchrl.collectors</span> <span class="kn">import</span> <span class="n">MultiaSyncDataCollector</span>
<span class="kn">from</span> <span class="nn">torchrl.data</span> <span class="kn">import</span> <span class="n">LazyMemmapStorage</span><span class="p">,</span> <span class="n">TensorDictReplayBuffer</span>
<span class="kn">from</span> <span class="nn">torchrl.envs</span> <span class="kn">import</span> <span class="n">EnvCreator</span><span class="p">,</span> <span class="n">ParallelEnv</span>
<span class="kn">from</span> <span class="nn">torchrl.envs.libs.gym</span> <span class="kn">import</span> <span class="n">GymEnv</span>
<span class="kn">from</span> <span class="nn">torchrl.envs.transforms</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CatFrames</span><span class="p">,</span>
    <span class="n">CatTensors</span><span class="p">,</span>
    <span class="n">Compose</span><span class="p">,</span>
    <span class="n">GrayScale</span><span class="p">,</span>
    <span class="n">ObservationNorm</span><span class="p">,</span>
    <span class="n">Resize</span><span class="p">,</span>
    <span class="n">ToTensorImage</span><span class="p">,</span>
    <span class="n">TransformedEnv</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">torchrl.envs.utils</span> <span class="kn">import</span> <span class="n">set_exploration_mode</span><span class="p">,</span> <span class="n">step_mdp</span>
<span class="kn">from</span> <span class="nn">torchrl.modules</span> <span class="kn">import</span> <span class="n">DuelingCnnDQNet</span><span class="p">,</span> <span class="n">EGreedyWrapper</span><span class="p">,</span> <span class="n">QValueActor</span>


<span class="k">def</span> <span class="nf">is_notebook</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">shell</span> <span class="o">=</span> <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="k">if</span> <span class="n">shell</span> <span class="o">==</span> <span class="s2">&quot;ZMQInteractiveShell&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>  <span class="c1"># Jupyter notebook or qtconsole</span>
        <span class="k">elif</span> <span class="n">shell</span> <span class="o">==</span> <span class="s2">&quot;TerminalInteractiveShell&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>  <span class="c1"># Terminal running IPython</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>  <span class="c1"># Other type (?)</span>
    <span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>  <span class="c1"># Probably standard Python interpreter</span>
</pre></div>
</div>
<section id="hyperparameters">
<h2>Hyperparameters<a class="headerlink" href="#hyperparameters" title="Permalink to this heading">¶</a></h2>
<p>Let’s start with our hyperparameters. This is a totally arbitrary list of
hyperparams that we found to work well in practice. Hopefully the performance
of the algorithm should not be too sentitive to slight variations of these.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># hyperparams</span>

<span class="c1"># the learning rate of the optimizer</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">2e-3</span>
<span class="c1"># the beta parameters of Adam</span>
<span class="n">betas</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)</span>
<span class="c1"># gamma decay factor</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="c1"># lambda decay factor (see second the part with TD(lambda)</span>
<span class="n">lmbda</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="c1"># total frames collected in the environment. In other implementations, the user defines a maximum number of episodes.</span>
<span class="c1"># This is harder to do with our data collectors since they return batches of N collected frames, where N is a constant.</span>
<span class="c1"># However, one can easily get the same restriction on number of episodes by breaking the training loop when a certain number</span>
<span class="c1"># episodes has been collected.</span>
<span class="n">total_frames</span> <span class="o">=</span> <span class="mi">500</span>
<span class="c1"># Random frames used to initialize the replay buffer.</span>
<span class="n">init_random_frames</span> <span class="o">=</span> <span class="mi">100</span>
<span class="c1"># Frames in each batch collected.</span>
<span class="n">frames_per_batch</span> <span class="o">=</span> <span class="mi">32</span>
<span class="c1"># Optimization steps per batch collected</span>
<span class="n">n_optim</span> <span class="o">=</span> <span class="mi">4</span>
<span class="c1"># Frames sampled from the replay buffer at each optimization step</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="c1"># Size of the replay buffer in terms of frames</span>
<span class="n">buffer_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">total_frames</span><span class="p">,</span> <span class="mi">100000</span><span class="p">)</span>
<span class="c1"># Number of environments run in parallel in each data collector</span>
<span class="n">n_workers</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>

<span class="c1"># Smooth target network update decay parameter. This loosely corresponds to a 1/(1-tau) interval with hard target network update</span>
<span class="n">tau</span> <span class="o">=</span> <span class="mf">0.005</span>

<span class="c1"># Initial and final value of the epsilon factor in Epsilon-greedy exploration (notice that since our policy is deterministic exploration is crucial)</span>
<span class="n">eps_greedy_val</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">eps_greedy_val_env</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="c1"># To speed up learning, we set the bias of the last layer of our value network to a predefined value</span>
<span class="n">init_bias</span> <span class="o">=</span> <span class="mf">20.0</span>
</pre></div>
</div>
<p><strong>Note</strong>: for fast rendering of the tutorial <code class="docutils literal notranslate"><span class="pre">total_frames</span></code> hyperparameter
was set to a very low number. To get a reasonable performance, use a greater
value e.g. 500000</p>
</section>
<section id="building-the-environment">
<h2>Building the environment<a class="headerlink" href="#building-the-environment" title="Permalink to this heading">¶</a></h2>
<p>Our environment builder has three arguments:</p>
<ul class="simple">
<li><p>parallel: determines whether multiple environments have to be run in
parallel. We stack the transforms after the ParallelEnv to take advantage
of vectorization of the operations on device, although this would
techinally work with every single environment attached to its own set of
transforms.</p></li>
<li><p>mean and standard deviation: we normalize the observations (images)
with two parameters computed from a random rollout in the environment.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_env</span><span class="p">(</span><span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>

    <span class="k">if</span> <span class="n">parallel</span><span class="p">:</span>
        <span class="n">base_env</span> <span class="o">=</span> <span class="n">ParallelEnv</span><span class="p">(</span>
            <span class="n">n_workers</span><span class="p">,</span>
            <span class="n">EnvCreator</span><span class="p">(</span>
                <span class="k">lambda</span><span class="p">:</span> <span class="n">GymEnv</span><span class="p">(</span>
                    <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">from_pixels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pixels_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
                <span class="p">)</span>
            <span class="p">),</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">base_env</span> <span class="o">=</span> <span class="n">GymEnv</span><span class="p">(</span>
            <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">from_pixels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pixels_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
        <span class="p">)</span>

    <span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span>
        <span class="n">base_env</span><span class="p">,</span>
        <span class="n">Compose</span><span class="p">(</span>
            <span class="n">ToTensorImage</span><span class="p">(),</span>
            <span class="n">GrayScale</span><span class="p">(),</span>
            <span class="n">Resize</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
            <span class="n">ObservationNorm</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pixels&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">standard_normal</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">CatFrames</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pixels&quot;</span><span class="p">]),</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">env</span>
</pre></div>
</div>
<p>Compute normalizing constants:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dummy_env</span> <span class="o">=</span> <span class="n">make_env</span><span class="p">()</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">dummy_env</span><span class="o">.</span><span class="n">transform</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reset</span><span class="p">()[</span><span class="s2">&quot;pixels&quot;</span><span class="p">]</span>
<span class="n">m</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">v</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">m</span><span class="p">,</span> <span class="n">s</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(0.9927790760993958, 0.0761055275797844)
</pre></div>
</div>
</section>
<section id="the-problem">
<h2>The problem<a class="headerlink" href="#the-problem" title="Permalink to this heading">¶</a></h2>
<p>We can have a look at the problem by generating a video with a random
policy. From gym:</p>
<p><em>A pole is attached by an un-actuated joint to a cart, which moves along a</em>
<em>frictionless track. The pendulum is placed upright on the cart and the</em>
<em>goal is to balance the pole by applying forces in the left and right</em>
<em>direction on the cart.</em></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># we add a CatTensors transform to copy the &quot;pixels&quot; before it&#39;s being replaced by its grayscale, resized version</span>
<span class="n">dummy_env</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">CatTensors</span><span class="p">([</span><span class="s2">&quot;pixels&quot;</span><span class="p">],</span> <span class="s2">&quot;pixels_save&quot;</span><span class="p">,</span> <span class="n">del_keys</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="c1"># we omit the policy from the rollout call: this will generate random actions from the env.action_spec attribute</span>
<span class="n">eval_rollout</span> <span class="o">=</span> <span class="n">dummy_env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

<span class="c1"># imageio.mimwrite(&#39;cartpole_random.mp4&#39;, eval_rollout[&quot;pixels_save&quot;].numpy(), fps=30)</span>
<span class="c1"># Video(&#39;cartpole_random.mp4&#39;, width=480, height=360)</span>
</pre></div>
</div>
</section>
<section id="building-the-model-deep-q-network">
<h2>Building the model (Deep Q-network)<a class="headerlink" href="#building-the-model-deep-q-network" title="Permalink to this heading">¶</a></h2>
<p>The following function builds a <code class="docutils literal notranslate"><span class="pre">DuelingCnnDQNet</span></code> object which is a
simple CNN followed by a two-layer MLP. The only trick used here is that
the action values (i.e. left and right action value) are computed using</p>
<div class="math notranslate nohighlight">
\[values = baseline(observation) + values(observation) - values(observation).mean()\]</div>
<p>where <code class="docutils literal notranslate"><span class="pre">baseline</span></code> is a <code class="docutils literal notranslate"><span class="pre">num_obs</span> <span class="pre">-&gt;</span> <span class="pre">1</span></code> function and <code class="docutils literal notranslate"><span class="pre">values</span></code> is a
<code class="docutils literal notranslate"><span class="pre">num_obs</span> <span class="pre">-&gt;</span> <span class="pre">num_actions</span></code> function.</p>
<p>Our network is wrapped in a <code class="docutils literal notranslate"><span class="pre">QValueActor</span></code>, which will read the state-action
values, pick up the one with the maximum value and write all those results
in the input <code class="docutils literal notranslate"><span class="pre">TensorDict</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_model</span><span class="p">():</span>
    <span class="n">cnn_kwargs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;num_cells&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span>
        <span class="s2">&quot;kernel_sizes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="s2">&quot;strides&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="s2">&quot;activation_class&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">,</span>
        <span class="s2">&quot;squeeze_output&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;aggregator_class&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">,</span>
        <span class="s2">&quot;aggregator_kwargs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;output_size&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)},</span>
    <span class="p">}</span>
    <span class="n">mlp_kwargs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;depth&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="s2">&quot;num_cells&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="mi">64</span><span class="p">,</span>
            <span class="mi">64</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="c1"># &quot;out_features&quot;: dummy_env.action_spec.shape[-1],</span>
        <span class="s2">&quot;activation_class&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">DuelingCnnDQNet</span><span class="p">(</span>
        <span class="n">dummy_env</span><span class="o">.</span><span class="n">action_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cnn_kwargs</span><span class="p">,</span> <span class="n">mlp_kwargs</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">init_bias</span><span class="p">)</span>

    <span class="n">actor</span> <span class="o">=</span> <span class="n">QValueActor</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pixels&quot;</span><span class="p">],</span> <span class="n">spec</span><span class="o">=</span><span class="n">dummy_env</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># init actor</span>
    <span class="n">tensordict</span> <span class="o">=</span> <span class="n">dummy_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;reset results:&quot;</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span>
    <span class="n">actor</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Q-value network results:&quot;</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span>

    <span class="c1"># make functional</span>
    <span class="c1"># here&#39;s an explicit way of creating the parameters and buffer tensordict.</span>
    <span class="c1"># Alternatively, we could have used `params = make_functional(actor)` from</span>
    <span class="c1"># tensordict.nn</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">actor</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()},</span> <span class="p">[])</span>
    <span class="n">buffers</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">actor</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">()},</span> <span class="p">[])</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">buffers</span><span class="p">)</span><span class="o">.</span><span class="n">unflatten_keys</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>  <span class="c1"># creates a nested TensorDict</span>
    <span class="n">factor</span> <span class="o">=</span> <span class="n">get_functional</span><span class="p">(</span><span class="n">actor</span><span class="p">)</span>

    <span class="c1"># creating the target parameters is fairly easy with tensordict:</span>
    <span class="p">(</span><span class="n">params_target</span><span class="p">,)</span> <span class="o">=</span> <span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">to_tensordict</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),)</span>

    <span class="c1"># we wrap our actor in an EGreedyWrapper for data collection</span>
    <span class="n">actor_explore</span> <span class="o">=</span> <span class="n">EGreedyWrapper</span><span class="p">(</span>
        <span class="n">actor</span><span class="p">,</span>
        <span class="n">annealing_num_steps</span><span class="o">=</span><span class="n">total_frames</span><span class="p">,</span>
        <span class="n">eps_init</span><span class="o">=</span><span class="n">eps_greedy_val</span><span class="p">,</span>
        <span class="n">eps_end</span><span class="o">=</span><span class="n">eps_greedy_val_env</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">factor</span><span class="p">,</span> <span class="n">actor</span><span class="p">,</span> <span class="n">actor_explore</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">params_target</span>
</pre></div>
</div>
<p>When creating the model, we initialize the network with an environment reset.
We print the resulting tensordict instance to get an idea of what
<code class="docutils literal notranslate"><span class="pre">QValueActor</span></code> (pay attention to the keys <code class="docutils literal notranslate"><span class="pre">action</span></code>, <code class="docutils literal notranslate"><span class="pre">action_value</span></code> and
<code class="docutils literal notranslate"><span class="pre">chosen_action_value</span></code> after calling the policy).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span>
    <span class="n">factor</span><span class="p">,</span>
    <span class="n">actor</span><span class="p">,</span>
    <span class="n">actor_explore</span><span class="p">,</span>
    <span class="n">params</span><span class="p">,</span>
    <span class="n">params_target</span><span class="p">,</span>
<span class="p">)</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">()</span>
<span class="n">params_flat</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">flatten_keys</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">params_target_flat</span> <span class="o">=</span> <span class="n">params_target</span><span class="o">.</span><span class="n">flatten_keys</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>reset results: TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([4, 64, 64]), device=cpu, dtype=torch.float32, is_shared=False),
        pixels_save: Tensor(shape=torch.Size([400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
Q-value network results: TensorDict(
    fields={
        action: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),
        action_value: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),
        chosen_action_value: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([4, 64, 64]), device=cpu, dtype=torch.float32, is_shared=False),
        pixels_save: Tensor(shape=torch.Size([400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
</section>
<section id="regular-dqn">
<h2>Regular DQN<a class="headerlink" href="#regular-dqn" title="Permalink to this heading">¶</a></h2>
<p>We’ll start with a simple implementation of DQN where the returns are
computed without bootstrapping, i.e.</p>
<blockquote>
<div><p>return = reward + gamma * value_next_step * not_terminated</p>
</div></blockquote>
<p>We start with the <em>replay buffer</em>. We’ll use a regular replay buffer,
although a prioritized RB could improve the performance significantly.
We place the storage on disk using <code class="docutils literal notranslate"><span class="pre">LazyMemmapStorage</span></code>. The only requirement
of this storage is that the data given to it must always have the same
shape. This storage will be instantiated later.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">TensorDictReplayBuffer</span><span class="p">(</span>
    <span class="n">storage</span><span class="o">=</span><span class="n">LazyMemmapStorage</span><span class="p">(</span><span class="n">buffer_size</span><span class="p">),</span>
    <span class="n">prefetch</span><span class="o">=</span><span class="n">n_optim</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Our <em>data collector</em> will run two parallel environments in parallel, and
deliver the collected tensordicts once at a time to the main process. We’ll
use the <code class="docutils literal notranslate"><span class="pre">MultiaSyncDataCollector</span></code> collector, which will collect data while
the optimization is taking place.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data_collector</span> <span class="o">=</span> <span class="n">MultiaSyncDataCollector</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">make_env</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">s</span><span class="p">),</span>
        <span class="n">make_env</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">s</span><span class="p">),</span>
    <span class="p">],</span>  <span class="c1"># 2 collectors, each with an set of `num_workers` environments being run in parallel</span>
    <span class="n">policy</span><span class="o">=</span><span class="n">actor_explore</span><span class="p">,</span>
    <span class="n">frames_per_batch</span><span class="o">=</span><span class="n">frames_per_batch</span><span class="p">,</span>
    <span class="n">total_frames</span><span class="o">=</span><span class="n">total_frames</span><span class="p">,</span>
    <span class="n">exploration_mode</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">,</span>  <span class="c1"># this is the default behaviour: the collector runs in `&quot;random&quot;` (or explorative) mode</span>
    <span class="n">devices</span><span class="o">=</span><span class="p">[</span><span class="n">device</span><span class="p">,</span> <span class="n">device</span><span class="p">],</span>  <span class="c1"># each collector can sit on a different device</span>
    <span class="n">passing_devices</span><span class="o">=</span><span class="p">[</span><span class="n">device</span><span class="p">,</span> <span class="n">device</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Our <em>optimizer</em> and the env used for evaluation</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">params_flat</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">lr</span><span class="p">)</span>
<span class="n">dummy_env</span> <span class="o">=</span> <span class="n">make_env</span><span class="p">(</span><span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">actor_explore</span><span class="p">(</span><span class="n">dummy_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        action: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),
        action_value: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),
        chosen_action_value: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([4, 64, 64]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<p>Various lists that will contain the values recorded for evaluation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">evals</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">traj_lengths_eval</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">grad_vals</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">traj_lengths</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">mavgs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">traj_count</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">prev_traj_count</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
<section id="training-loop">
<h3>Training loop<a class="headerlink" href="#training-loop" title="Permalink to this heading">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">total_frames</span><span class="p">)</span>
<span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_collector</span><span class="p">):</span>
    <span class="c1"># trajectories are padded to be stored in the same tensordict: since we do not care about consecutive step, we&#39;ll just mask the tensordict and get the flattened representation instead.</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;mask&quot;</span><span class="p">]</span>
    <span class="n">current_frames</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">current_frames</span><span class="p">)</span>

    <span class="c1"># We store the values on the replay buffer, after placing them on CPU. When called for the first time, this will instantiate our storage object which will print its content.</span>
    <span class="n">replay_buffer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>

    <span class="c1"># some logging</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">frames</span><span class="p">):</span>
        <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_frames</span> <span class="o">+</span> <span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_frames</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="n">done</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">traj_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;step_count&quot;</span><span class="p">][</span><span class="n">done</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="c1"># check that we have enough data to start training</span>
    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">frames</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">init_random_frames</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_optim</span><span class="p">):</span>
            <span class="c1"># sample from the RB and send to device</span>
            <span class="n">sampled_data</span> <span class="o">=</span> <span class="n">replay_buffer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
            <span class="n">sampled_data</span> <span class="o">=</span> <span class="n">sampled_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># collect data from RB</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">sampled_data</span><span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">sampled_data</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">reward</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">sampled_data</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

            <span class="c1"># Compute action value (of the action actually taken) at time t</span>
            <span class="n">sampled_data_out</span> <span class="o">=</span> <span class="n">sampled_data</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">actor</span><span class="o">.</span><span class="n">in_keys</span><span class="p">)</span>
            <span class="n">sampled_data_out</span> <span class="o">=</span> <span class="n">factor</span><span class="p">(</span><span class="n">sampled_data_out</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
            <span class="n">action_value</span> <span class="o">=</span> <span class="n">sampled_data_out</span><span class="p">[</span><span class="s2">&quot;action_value&quot;</span><span class="p">]</span>
            <span class="n">action_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">action_value</span> <span class="o">*</span> <span class="n">action</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">action_value</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="c1"># compute best action value for the next step, using target parameters</span>
                <span class="n">tdstep</span> <span class="o">=</span> <span class="n">step_mdp</span><span class="p">(</span><span class="n">sampled_data</span><span class="p">)</span>
                <span class="n">next_value</span> <span class="o">=</span> <span class="n">factor</span><span class="p">(</span>
                    <span class="n">tdstep</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">actor</span><span class="o">.</span><span class="n">in_keys</span><span class="p">),</span>
                    <span class="n">params</span><span class="o">=</span><span class="n">params_target</span><span class="p">,</span>
                <span class="p">)[</span><span class="s2">&quot;chosen_action_value&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">exp_value</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">next_value</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">done</span><span class="p">)</span>
            <span class="k">assert</span> <span class="n">exp_value</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">action_value</span><span class="o">.</span><span class="n">shape</span>
            <span class="c1"># we use MSE loss but L1 or smooth L1 should also work</span>
            <span class="n">error</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">exp_value</span><span class="p">,</span> <span class="n">action_value</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="n">error</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="n">gv</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params_flat</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_value_</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">params_flat</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># update of the target parameters</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">p1</span><span class="p">)</span> <span class="ow">in</span> <span class="n">params_flat</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">p2</span> <span class="o">=</span> <span class="n">params_target_flat</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                <span class="n">params_target_flat</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">p1</span><span class="o">.</span><span class="n">data</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">p2</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

        <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;error: </span><span class="si">{</span><span class="n">error</span><span class="si">:</span><span class="s2"> 4.4f</span><span class="si">}</span><span class="s2">, value: </span><span class="si">{</span><span class="n">action_value</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2"> 4.4f</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="n">actor_explore</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">current_frames</span><span class="p">)</span>

        <span class="c1"># logs</span>
        <span class="k">with</span> <span class="n">set_exploration_mode</span><span class="p">(</span><span class="s2">&quot;mode&quot;</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># execute a rollout. The `set_exploration_mode(&quot;mode&quot;)` has no effect here since the policy is deterministic, but we add it for completeness</span>
            <span class="n">eval_rollout</span> <span class="o">=</span> <span class="n">dummy_env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">actor</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="n">grad_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">gv</span><span class="p">))</span>
        <span class="n">traj_lengths_eval</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">eval_rollout</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">evals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">eval_rollout</span><span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mavgs</span><span class="p">):</span>
            <span class="n">mavgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evals</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.05</span> <span class="o">+</span> <span class="n">mavgs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.95</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mavgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evals</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action_value</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">traj_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prev_traj_count</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">prev_traj_count</span> <span class="o">=</span> <span class="n">traj_count</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># plots</span>
        <span class="k">if</span> <span class="n">j</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_notebook</span><span class="p">():</span>
                <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">evals</span><span class="p">)</span> <span class="p">:],</span> <span class="n">evals</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;return&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">mavgs</span><span class="p">)</span> <span class="p">:],</span> <span class="n">mavgs</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mavg&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;trajectory length (= return)&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj_count</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">evals</span><span class="p">)</span> <span class="p">:],</span> <span class="n">evals</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;return&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj_count</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">mavgs</span><span class="p">)</span> <span class="p">:],</span> <span class="n">mavgs</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mavg&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;trajectories collected&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span> <span class="p">:],</span> <span class="n">losses</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span> <span class="p">:],</span> <span class="n">values</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">grad_vals</span><span class="p">)</span> <span class="p">:],</span> <span class="n">grad_vals</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;grad norm&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">traj_lengths</span><span class="p">):</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj_lengths</span><span class="p">)</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;batches&quot;</span><span class="p">)</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;traj length (training)&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;dqn_td0.png&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_notebook</span><span class="p">():</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># update policy weights</span>
    <span class="n">data_collector</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">()</span>

<span class="k">if</span> <span class="n">is_notebook</span><span class="p">():</span>
    <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">())</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../_images/sphx_glr_coding_dqn_001.png" srcset="../_images/sphx_glr_coding_dqn_001.png" alt="coding dqn" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_coding_dqn_002.png" srcset="../_images/sphx_glr_coding_dqn_002.png" alt="loss, value, grad norm, traj length (training)" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/500 [00:00&lt;?, ?it/s]
  6%|6         | 32/500 [00:06&lt;01:35,  4.89it/s]Creating a MemmapStorage...
The storage is being created:
        action: /tmp/tmp1l_3dk4m, 0.00762939453125 Mb of storage (size: torch.Size([500, 2])).
        action_value: /tmp/tmp21ovrxxd, 0.003814697265625 Mb of storage (size: torch.Size([500, 2])).
        chosen_action_value: /tmp/tmpejw51047, 0.0019073486328125 Mb of storage (size: torch.Size([500, 1])).
        done: /tmp/tmpf2qpbq7r, 0.000476837158203125 Mb of storage (size: torch.Size([500, 1])).
        index: /tmp/tmprj_m39j2, 0.0019073486328125 Mb of storage (size: torch.Size([500])).
        mask: /tmp/tmph1v0i3a0, 0.000476837158203125 Mb of storage (size: torch.Size([500])).
        pixels: /tmp/tmp20by6xhd, 31.25 Mb of storage (size: torch.Size([500, 4, 64, 64])).
        reward: /tmp/tmpglqyt160, 0.0019073486328125 Mb of storage (size: torch.Size([500, 1])).
        step_count: /tmp/tmp_666_9y9, 0.003814697265625 Mb of storage (size: torch.Size([500])).
        traj_ids: /tmp/tmpv_l9anhc, 0.003814697265625 Mb of storage (size: torch.Size([500])).
        (&#39;next&#39;, &#39;pixels&#39;): /tmp/tmp5q2lxd6b, 31.25 Mb of storage (size: torch.Size([500, 4, 64, 64])).

 13%|#2        | 64/500 [00:06&lt;00:38, 11.34it/s]
 19%|#9        | 96/500 [00:10&lt;00:43,  9.28it/s]
error:  34.3328, value:  19.9695:  19%|#9        | 96/500 [00:11&lt;00:43,  9.28it/s]
error:  34.3328, value:  19.9695:  26%|##5       | 128/500 [00:11&lt;00:27, 13.31it/s]
error:  12.1961, value:  19.5104:  26%|##5       | 128/500 [00:12&lt;00:27, 13.31it/s]
error:  12.1961, value:  19.5104:  32%|###2      | 160/500 [00:13&lt;00:23, 14.43it/s]
error:  31.8997, value:  19.2111:  32%|###2      | 160/500 [00:14&lt;00:23, 14.43it/s]
error:  31.8997, value:  19.2111:  38%|###8      | 192/500 [00:14&lt;00:16, 18.33it/s]
error:  10.7062, value:  19.5417:  38%|###8      | 192/500 [00:15&lt;00:16, 18.33it/s]
error:  10.7062, value:  19.5417:  45%|####4     | 224/500 [00:20&lt;00:28,  9.75it/s]
error:  28.0678, value:  20.9726:  45%|####4     | 224/500 [00:21&lt;00:28,  9.75it/s]
error:  28.0678, value:  20.9726:  51%|#####1    | 256/500 [00:22&lt;00:20, 11.96it/s]
error:  20.7803, value:  17.9396:  51%|#####1    | 256/500 [00:22&lt;00:20, 11.96it/s]
error:  20.7803, value:  17.9396:  58%|#####7    | 288/500 [00:24&lt;00:17, 12.24it/s]
error:  18.1335, value:  18.3466:  58%|#####7    | 288/500 [00:25&lt;00:17, 12.24it/s]
error:  18.1335, value:  18.3466:  64%|######4   | 320/500 [00:27&lt;00:14, 12.18it/s]
error:  23.5000, value:  19.8063:  64%|######4   | 320/500 [00:28&lt;00:14, 12.18it/s]
error:  23.5000, value:  19.8063:  70%|#######   | 352/500 [00:29&lt;00:11, 12.79it/s]
error:  7.3759, value:  19.7590:  70%|#######   | 352/500 [00:30&lt;00:11, 12.79it/s]
error:  7.3759, value:  19.7590:  77%|#######6  | 384/500 [00:31&lt;00:08, 14.03it/s]
error:  45.6204, value:  18.3932:  77%|#######6  | 384/500 [00:32&lt;00:08, 14.03it/s]
error:  45.6204, value:  18.3932:  83%|########3 | 416/500 [00:35&lt;00:07, 11.92it/s]
error:  28.8345, value:  18.4719:  83%|########3 | 416/500 [00:35&lt;00:07, 11.92it/s]
error:  28.8345, value:  18.4719:  90%|########9 | 448/500 [00:36&lt;00:03, 14.46it/s]
error:  18.5943, value:  19.6253:  90%|########9 | 448/500 [00:36&lt;00:03, 14.46it/s]
error:  18.5943, value:  19.6253:  96%|#########6| 480/500 [00:40&lt;00:01, 11.46it/s]
error:  1.9974, value:  20.0813:  96%|#########6| 480/500 [00:41&lt;00:01, 11.46it/s]
error:  1.9974, value:  20.0813: : 512it [00:42, 12.90it/s]
error:  40.1958, value:  18.6198: : 512it [00:42, 12.90it/s]
</pre></div>
</div>
<p><strong>Note</strong>: As already mentioned above, to get a more reasonable performance,
use a greater value for <code class="docutils literal notranslate"><span class="pre">total_frames</span></code> e.g. 500000.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">&quot;dqn_td0.png&quot;</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_coding_dqn_003.png" srcset="../_images/sphx_glr_coding_dqn_003.png" alt="coding dqn" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(-0.5, 1499.5, 1499.5, -0.5)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># save results</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;frames&quot;</span><span class="p">:</span> <span class="n">frames</span><span class="p">,</span>
        <span class="s2">&quot;evals&quot;</span><span class="p">:</span> <span class="n">evals</span><span class="p">,</span>
        <span class="s2">&quot;mavgs&quot;</span><span class="p">:</span> <span class="n">mavgs</span><span class="p">,</span>
        <span class="s2">&quot;losses&quot;</span><span class="p">:</span> <span class="n">losses</span><span class="p">,</span>
        <span class="s2">&quot;values&quot;</span><span class="p">:</span> <span class="n">values</span><span class="p">,</span>
        <span class="s2">&quot;grad_vals&quot;</span><span class="p">:</span> <span class="n">grad_vals</span><span class="p">,</span>
        <span class="s2">&quot;traj_lengths_training&quot;</span><span class="p">:</span> <span class="n">traj_lengths</span><span class="p">,</span>
        <span class="s2">&quot;traj_count&quot;</span><span class="p">:</span> <span class="n">traj_count</span><span class="p">,</span>
        <span class="s2">&quot;weights&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">params</span><span class="p">,),</span>
    <span class="p">},</span>
    <span class="s2">&quot;saved_results_td0.pt&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="td-lambda">
<h2>TD-lambda<a class="headerlink" href="#td-lambda" title="Permalink to this heading">¶</a></h2>
<p>We can improve the above algorithm by getting a better estimate of the
return, using not only the next state value but the whole sequence of rewards
and values that follow a particular step.</p>
<p>TorchRL provides a vectorized version of TD(lambda) named
<code class="docutils literal notranslate"><span class="pre">vec_td_lambda_advantage_estimate</span></code>. We’ll use this to obtain a target
value that the value network will be trained to match.</p>
<p>The big difference in this implementation is that we’ll store entire
trajectories and not single steps in the replay buffer. This will be done
automatically as long as we’re not “flattening” the tensordict collected
using its mask: by keeping a shape <code class="docutils literal notranslate"><span class="pre">[Batch</span> <span class="pre">x</span> <span class="pre">timesteps]</span></code> and giving this
to the RB, we’ll be creating a replay buffer of size
<code class="docutils literal notranslate"><span class="pre">[Capacity</span> <span class="pre">x</span> <span class="pre">timesteps]</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensordict.tensordict</span> <span class="kn">import</span> <span class="n">pad</span>
<span class="kn">from</span> <span class="nn">torchrl.objectives.value.functional</span> <span class="kn">import</span> <span class="n">vec_td_lambda_advantage_estimate</span>
</pre></div>
</div>
<p>We reset the actor, the RB and the collector</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span>
    <span class="n">factor</span><span class="p">,</span>
    <span class="n">actor</span><span class="p">,</span>
    <span class="n">actor_explore</span><span class="p">,</span>
    <span class="n">params</span><span class="p">,</span>
    <span class="n">params_target</span><span class="p">,</span>
<span class="p">)</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">()</span>
<span class="n">params_flat</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">flatten_keys</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">params_target_flat</span> <span class="o">=</span> <span class="n">params_target</span><span class="o">.</span><span class="n">flatten_keys</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>reset results: TensorDict(
    fields={
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([4, 64, 64]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
Q-value network results: TensorDict(
    fields={
        action: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),
        action_value: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),
        chosen_action_value: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([4, 64, 64]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">max_size</span> <span class="o">=</span> <span class="n">frames_per_batch</span> <span class="o">//</span> <span class="n">n_workers</span>

<span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">TensorDictReplayBuffer</span><span class="p">(</span>
    <span class="n">storage</span><span class="o">=</span><span class="n">LazyMemmapStorage</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="n">buffer_size</span> <span class="o">//</span> <span class="n">max_size</span><span class="p">)),</span>
    <span class="n">prefetch</span><span class="o">=</span><span class="n">n_optim</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">data_collector</span> <span class="o">=</span> <span class="n">MultiaSyncDataCollector</span><span class="p">(</span>
    <span class="p">[</span><span class="n">make_env</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">s</span><span class="p">),</span> <span class="n">make_env</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">s</span><span class="p">)],</span>
    <span class="n">policy</span><span class="o">=</span><span class="n">actor_explore</span><span class="p">,</span>
    <span class="n">frames_per_batch</span><span class="o">=</span><span class="n">frames_per_batch</span><span class="p">,</span>
    <span class="n">total_frames</span><span class="o">=</span><span class="n">total_frames</span><span class="p">,</span>
    <span class="n">exploration_mode</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">,</span>
    <span class="n">devices</span><span class="o">=</span><span class="p">[</span><span class="n">device</span><span class="p">,</span> <span class="n">device</span><span class="p">],</span>
    <span class="n">passing_devices</span><span class="o">=</span><span class="p">[</span><span class="n">device</span><span class="p">,</span> <span class="n">device</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>error:  40.1958, value:  18.6198: : 512it [00:53, 12.90it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">params_flat</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">lr</span><span class="p">)</span>
<span class="n">dummy_env</span> <span class="o">=</span> <span class="n">make_env</span><span class="p">(</span><span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">actor_explore</span><span class="p">(</span><span class="n">dummy_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        action: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),
        action_value: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),
        chosen_action_value: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([4, 64, 64]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">evals</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">traj_lengths_eval</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">grad_vals</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">traj_lengths</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">mavgs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">traj_count</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">prev_traj_count</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
<section id="id1">
<h3>Training loop<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h3>
<p>There are very few differences with the training loop above:</p>
<ul class="simple">
<li><p>The tensordict received by the collector is not masked but padded to the
desired shape (such that all tensordicts have the same shape of
<code class="docutils literal notranslate"><span class="pre">[Batch</span> <span class="pre">x</span> <span class="pre">max_size]</span></code>), and sent directly to the RB.</p></li>
<li><p>We use <code class="docutils literal notranslate"><span class="pre">vec_td_lambda_advantage_estimate</span></code> to compute the target value.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">total_frames</span><span class="p">)</span>
<span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_collector</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;mask&quot;</span><span class="p">]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pad</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">max_size</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <span class="n">current_frames</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">current_frames</span><span class="p">)</span>

    <span class="n">replay_buffer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">frames</span><span class="p">):</span>
        <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_frames</span> <span class="o">+</span> <span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_frames</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="n">done</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">traj_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;step_count&quot;</span><span class="p">][</span><span class="n">done</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">frames</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">init_random_frames</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_optim</span><span class="p">):</span>
            <span class="n">sampled_data</span> <span class="o">=</span> <span class="n">replay_buffer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">//</span> <span class="n">max_size</span><span class="p">)</span>
            <span class="n">sampled_data</span> <span class="o">=</span> <span class="n">sampled_data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">reward</span> <span class="o">=</span> <span class="n">sampled_data</span><span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">sampled_data</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">reward</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">sampled_data</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

            <span class="n">sampled_data_out</span> <span class="o">=</span> <span class="n">sampled_data</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">actor</span><span class="o">.</span><span class="n">in_keys</span><span class="p">)</span>
            <span class="n">sampled_data_out</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">factor</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">))(</span><span class="n">sampled_data_out</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
            <span class="n">action_value</span> <span class="o">=</span> <span class="n">sampled_data_out</span><span class="p">[</span><span class="s2">&quot;action_value&quot;</span><span class="p">]</span>
            <span class="n">action_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">action_value</span> <span class="o">*</span> <span class="n">action</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">action_value</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">tdstep</span> <span class="o">=</span> <span class="n">step_mdp</span><span class="p">(</span><span class="n">sampled_data</span><span class="p">)</span>
                <span class="n">next_value</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">factor</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">))(</span>
                    <span class="n">tdstep</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">actor</span><span class="o">.</span><span class="n">in_keys</span><span class="p">),</span> <span class="n">params</span>
                <span class="p">)</span>
                <span class="n">next_value</span> <span class="o">=</span> <span class="n">next_value</span><span class="p">[</span><span class="s2">&quot;chosen_action_value&quot;</span><span class="p">]</span>
            <span class="n">error</span> <span class="o">=</span> <span class="n">vec_td_lambda_advantage_estimate</span><span class="p">(</span>
                <span class="n">gamma</span><span class="p">,</span>
                <span class="n">lmbda</span><span class="p">,</span>
                <span class="n">action_value</span><span class="p">,</span>
                <span class="n">next_value</span><span class="p">,</span>
                <span class="n">reward</span><span class="p">,</span>
                <span class="n">done</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
            <span class="c1"># reward + gamma * next_value * (1 - done)</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">sampled_data</span><span class="p">[</span><span class="s2">&quot;mask&quot;</span><span class="p">]</span>
            <span class="n">error</span> <span class="o">=</span> <span class="n">error</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="c1"># assert exp_value.shape == action_value.shape</span>
            <span class="c1"># error = nn.functional.smooth_l1_loss(exp_value, action_value).mean()</span>
            <span class="c1"># error = nn.functional.mse_loss(exp_value, action_value)[mask].mean()</span>
            <span class="n">error</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="c1"># gv = sum([p.grad.pow(2).sum() for p in params_flat.values()]).sqrt()</span>
            <span class="c1"># nn.utils.clip_grad_value_(list(params_flat.values()), 1)</span>
            <span class="n">gv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">params_flat</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="mi">100</span><span class="p">)</span>

            <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">p1</span><span class="p">)</span> <span class="ow">in</span> <span class="n">params_flat</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">p2</span> <span class="o">=</span> <span class="n">params_target_flat</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                <span class="n">params_target_flat</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">p1</span><span class="o">.</span><span class="n">data</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">p2</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

        <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;error: </span><span class="si">{</span><span class="n">error</span><span class="si">:</span><span class="s2"> 4.4f</span><span class="si">}</span><span class="s2">, value: </span><span class="si">{</span><span class="n">action_value</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2"> 4.4f</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="n">actor_explore</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">current_frames</span><span class="p">)</span>

        <span class="c1"># logs</span>
        <span class="k">with</span> <span class="n">set_exploration_mode</span><span class="p">(</span><span class="s2">&quot;random&quot;</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1">#         eval_rollout = dummy_env.rollout(max_steps=1000, policy=actor_explore, auto_reset=True).cpu()</span>
            <span class="n">eval_rollout</span> <span class="o">=</span> <span class="n">dummy_env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span>
                <span class="n">max_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">actor</span><span class="p">,</span> <span class="n">auto_reset</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="n">grad_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">gv</span><span class="p">))</span>
        <span class="n">traj_lengths_eval</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">eval_rollout</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">evals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">eval_rollout</span><span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mavgs</span><span class="p">):</span>
            <span class="n">mavgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evals</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.05</span> <span class="o">+</span> <span class="n">mavgs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.95</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mavgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evals</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action_value</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">traj_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prev_traj_count</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">prev_traj_count</span> <span class="o">=</span> <span class="n">traj_count</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># plots</span>
        <span class="k">if</span> <span class="n">j</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_notebook</span><span class="p">():</span>
                <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">evals</span><span class="p">)</span> <span class="p">:],</span> <span class="n">evals</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;return&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">mavgs</span><span class="p">)</span> <span class="p">:],</span> <span class="n">mavgs</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mavg&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;trajectory length (= return)&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj_count</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">evals</span><span class="p">)</span> <span class="p">:],</span> <span class="n">evals</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;return&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj_count</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">mavgs</span><span class="p">)</span> <span class="p">:],</span> <span class="n">mavgs</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mavg&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;trajectories collected&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span> <span class="p">:],</span> <span class="n">losses</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span> <span class="p">:],</span> <span class="n">values</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">grad_vals</span><span class="p">)</span> <span class="p">:],</span> <span class="n">grad_vals</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;grad norm&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">traj_lengths</span><span class="p">):</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj_lengths</span><span class="p">)</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;batches&quot;</span><span class="p">)</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;traj length (training)&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;dqn_tdlambda.png&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_notebook</span><span class="p">():</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># update policy weights</span>
    <span class="n">data_collector</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">()</span>

<span class="k">if</span> <span class="n">is_notebook</span><span class="p">():</span>
    <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">())</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../_images/sphx_glr_coding_dqn_004.png" srcset="../_images/sphx_glr_coding_dqn_004.png" alt="coding dqn" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_coding_dqn_005.png" srcset="../_images/sphx_glr_coding_dqn_005.png" alt="loss, value, grad norm, traj length (training)" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/500 [00:00&lt;?, ?it/s]
error:  40.1958, value:  18.6198: : 512it [00:55,  9.16it/s]


  6%|6         | 32/500 [00:06&lt;01:42,  4.58it/s]Creating a MemmapStorage...
The storage is being created:
        action: /tmp/tmpw1gc7yqc, 0.0078125 Mb of storage (size: torch.Size([16, 32, 2])).
        action_value: /tmp/tmper6ii3u8, 0.00390625 Mb of storage (size: torch.Size([16, 32, 2])).
        chosen_action_value: /tmp/tmpzkbb62q_, 0.001953125 Mb of storage (size: torch.Size([16, 32, 1])).
        done: /tmp/tmpr6svml7x, 0.00048828125 Mb of storage (size: torch.Size([16, 32, 1])).
        index: /tmp/tmpag7g9t1e, 6.103515625e-05 Mb of storage (size: torch.Size([16])).
        mask: /tmp/tmpxh3595rv, 0.00048828125 Mb of storage (size: torch.Size([16, 32])).
        pixels: /tmp/tmp6ic0chsu, 32.0 Mb of storage (size: torch.Size([16, 32, 4, 64, 64])).
        reward: /tmp/tmp0qg5iy46, 0.001953125 Mb of storage (size: torch.Size([16, 32, 1])).
        step_count: /tmp/tmp8i559ahr, 0.00390625 Mb of storage (size: torch.Size([16, 32])).
        traj_ids: /tmp/tmpcnaumo2o, 0.00390625 Mb of storage (size: torch.Size([16, 32])).
        (&#39;next&#39;, &#39;pixels&#39;): /tmp/tmp104a_nk6, 32.0 Mb of storage (size: torch.Size([16, 32, 4, 64, 64])).


 13%|#2        | 64/500 [00:07&lt;00:42, 10.34it/s]

 19%|#9        | 96/500 [00:12&lt;00:49,  8.24it/s]

error:  9.4428, value:  7.5369:  19%|#9        | 96/500 [00:12&lt;00:49,  8.24it/s]

error:  9.4428, value:  7.5369:  26%|##5       | 128/500 [00:13&lt;00:32, 11.33it/s]

error:  11.7821, value:  8.8290:  26%|##5       | 128/500 [00:14&lt;00:32, 11.33it/s]

error:  11.7821, value:  8.8290:  32%|###2      | 160/500 [00:17&lt;00:33, 10.04it/s]

error:  10.6582, value:  9.3924:  32%|###2      | 160/500 [00:17&lt;00:33, 10.04it/s]

error:  10.6582, value:  9.3924:  38%|###8      | 192/500 [00:19&lt;00:27, 11.19it/s]

error:  74.7146, value:  10.7921:  38%|###8      | 192/500 [00:20&lt;00:27, 11.19it/s]

error:  74.7146, value:  10.7921:  45%|####4     | 224/500 [00:21&lt;00:22, 12.11it/s]

error:  10.5996, value:  12.9823:  45%|####4     | 224/500 [00:22&lt;00:22, 12.11it/s]

error:  10.5996, value:  12.9823:  51%|#####1    | 256/500 [00:24&lt;00:21, 11.61it/s]

error:  6.9719, value:  11.9211:  51%|#####1    | 256/500 [00:25&lt;00:21, 11.61it/s]

error:  6.9719, value:  11.9211:  58%|#####7    | 288/500 [00:25&lt;00:13, 15.25it/s]

error:  29.2837, value:  17.0055:  58%|#####7    | 288/500 [00:25&lt;00:13, 15.25it/s]

error:  29.2837, value:  17.0055:  64%|######4   | 320/500 [00:27&lt;00:12, 14.32it/s]

error:  6.6955, value:  14.3260:  64%|######4   | 320/500 [00:28&lt;00:12, 14.32it/s]

error:  6.6955, value:  14.3260:  70%|#######   | 352/500 [00:30&lt;00:11, 13.29it/s]

error:  3.3747, value:  9.3487:  70%|#######   | 352/500 [00:31&lt;00:11, 13.29it/s]

error:  3.3747, value:  9.3487:  77%|#######6  | 384/500 [00:32&lt;00:07, 15.24it/s]

error:  12.0512, value:  11.0987:  77%|#######6  | 384/500 [00:32&lt;00:07, 15.24it/s]

error:  12.0512, value:  11.0987:  83%|########3 | 416/500 [00:34&lt;00:05, 14.82it/s]

error:  5.1704, value:  11.2637:  83%|########3 | 416/500 [00:35&lt;00:05, 14.82it/s]

error:  5.1704, value:  11.2637:  90%|########9 | 448/500 [00:35&lt;00:03, 16.15it/s]

error:  1.5493, value:  7.3087:  90%|########9 | 448/500 [00:36&lt;00:03, 16.15it/s]

error:  1.5493, value:  7.3087:  96%|#########6| 480/500 [00:37&lt;00:01, 17.61it/s]

error:  14.8016, value:  1.0519:  96%|#########6| 480/500 [00:38&lt;00:01, 17.61it/s]

error:  14.8016, value:  1.0519: : 512it [00:39, 17.71it/s]

error:  8.0462, value:  0.9057: : 512it [00:39, 17.71it/s]
</pre></div>
</div>
<p><strong>Note</strong>: As already mentioned above, to get a more reasonable performance,
use a greater value for <code class="docutils literal notranslate"><span class="pre">total_frames</span></code> e.g. 500000.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">&quot;dqn_tdlambda.png&quot;</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_coding_dqn_006.png" srcset="../_images/sphx_glr_coding_dqn_006.png" alt="coding dqn" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(-0.5, 1499.5, 1499.5, -0.5)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># save results</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;frames&quot;</span><span class="p">:</span> <span class="n">frames</span><span class="p">,</span>
        <span class="s2">&quot;evals&quot;</span><span class="p">:</span> <span class="n">evals</span><span class="p">,</span>
        <span class="s2">&quot;mavgs&quot;</span><span class="p">:</span> <span class="n">mavgs</span><span class="p">,</span>
        <span class="s2">&quot;losses&quot;</span><span class="p">:</span> <span class="n">losses</span><span class="p">,</span>
        <span class="s2">&quot;values&quot;</span><span class="p">:</span> <span class="n">values</span><span class="p">,</span>
        <span class="s2">&quot;grad_vals&quot;</span><span class="p">:</span> <span class="n">grad_vals</span><span class="p">,</span>
        <span class="s2">&quot;traj_lengths_training&quot;</span><span class="p">:</span> <span class="n">traj_lengths</span><span class="p">,</span>
        <span class="s2">&quot;traj_count&quot;</span><span class="p">:</span> <span class="n">traj_count</span><span class="p">,</span>
        <span class="s2">&quot;weights&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">params</span><span class="p">,),</span>
    <span class="p">},</span>
    <span class="s2">&quot;saved_results_tdlambda.pt&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Let’s compare the results on a single plot. Because the TD(lambda) version
works better, we’ll have fewer episodes collected for a given number of
frames (as there are more frames per episode).</p>
<p><strong>Note</strong>: As already mentioned above, to get a more reasonable performance,
use a greater value for <code class="docutils literal notranslate"><span class="pre">total_frames</span></code> e.g. 500000.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">load_td0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;saved_results_td0.pt&quot;</span><span class="p">)</span>
<span class="n">load_tdlambda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;saved_results_tdlambda.pt&quot;</span><span class="p">)</span>
<span class="n">frames_td0</span> <span class="o">=</span> <span class="n">load_td0</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]</span>
<span class="n">frames_tdlambda</span> <span class="o">=</span> <span class="n">load_tdlambda</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]</span>
<span class="n">evals_td0</span> <span class="o">=</span> <span class="n">load_td0</span><span class="p">[</span><span class="s2">&quot;evals&quot;</span><span class="p">]</span>
<span class="n">evals_tdlambda</span> <span class="o">=</span> <span class="n">load_tdlambda</span><span class="p">[</span><span class="s2">&quot;evals&quot;</span><span class="p">]</span>
<span class="n">mavgs_td0</span> <span class="o">=</span> <span class="n">load_td0</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">]</span>
<span class="n">mavgs_tdlambda</span> <span class="o">=</span> <span class="n">load_tdlambda</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">]</span>
<span class="n">losses_td0</span> <span class="o">=</span> <span class="n">load_td0</span><span class="p">[</span><span class="s2">&quot;losses&quot;</span><span class="p">]</span>
<span class="n">losses_tdlambda</span> <span class="o">=</span> <span class="n">load_tdlambda</span><span class="p">[</span><span class="s2">&quot;losses&quot;</span><span class="p">]</span>
<span class="n">values_td0</span> <span class="o">=</span> <span class="n">load_td0</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">]</span>
<span class="n">values_tdlambda</span> <span class="o">=</span> <span class="n">load_tdlambda</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">]</span>
<span class="n">grad_vals_td0</span> <span class="o">=</span> <span class="n">load_td0</span><span class="p">[</span><span class="s2">&quot;grad_vals&quot;</span><span class="p">]</span>
<span class="n">grad_vals_tdlambda</span> <span class="o">=</span> <span class="n">load_tdlambda</span><span class="p">[</span><span class="s2">&quot;grad_vals&quot;</span><span class="p">]</span>
<span class="n">traj_lengths_td0</span> <span class="o">=</span> <span class="n">load_td0</span><span class="p">[</span><span class="s2">&quot;traj_lengths_training&quot;</span><span class="p">]</span>
<span class="n">traj_lengths_tdlambda</span> <span class="o">=</span> <span class="n">load_tdlambda</span><span class="p">[</span><span class="s2">&quot;traj_lengths_training&quot;</span><span class="p">]</span>
<span class="n">traj_count_td0</span> <span class="o">=</span> <span class="n">load_td0</span><span class="p">[</span><span class="s2">&quot;traj_count&quot;</span><span class="p">]</span>
<span class="n">traj_count_tdlambda</span> <span class="o">=</span> <span class="n">load_tdlambda</span><span class="p">[</span><span class="s2">&quot;traj_count&quot;</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">evals_td0</span><span class="p">)</span> <span class="p">:],</span> <span class="n">evals_td0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;return (td0)&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">evals_tdlambda</span><span class="p">)</span> <span class="p">:],</span>
    <span class="n">evals_tdlambda</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;return (td(lambda))&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">mavgs_td0</span><span class="p">)</span> <span class="p">:],</span> <span class="n">mavgs_td0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mavg (td0)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">mavgs_tdlambda</span><span class="p">)</span> <span class="p">:],</span> <span class="n">mavgs_tdlambda</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mavg (td(lambda))&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;trajectory length (= return)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj_count_td0</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">evals_td0</span><span class="p">)</span> <span class="p">:],</span> <span class="n">evals_td0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;return (td0)&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">traj_count_tdlambda</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">evals_tdlambda</span><span class="p">)</span> <span class="p">:],</span>
    <span class="n">evals_tdlambda</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;return (td(lambda))&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj_count_td0</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">mavgs_td0</span><span class="p">)</span> <span class="p">:],</span> <span class="n">mavgs_td0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mavg (td0)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">traj_count_tdlambda</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">mavgs_tdlambda</span><span class="p">)</span> <span class="p">:],</span>
    <span class="n">mavgs_tdlambda</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mavg (td(lambda))&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;trajectories collected&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">losses_td0</span><span class="p">)</span> <span class="p">:],</span> <span class="n">losses_td0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;loss (td0)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">losses_tdlambda</span><span class="p">)</span> <span class="p">:],</span> <span class="n">losses_tdlambda</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;loss (td(lambda))&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">values_td0</span><span class="p">)</span> <span class="p">:],</span> <span class="n">values_td0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;values (td0)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">values_tdlambda</span><span class="p">)</span> <span class="p">:],</span> <span class="n">values_tdlambda</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;values (td(lambda))&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">grad_vals_td0</span><span class="p">)</span> <span class="p">:],</span> <span class="n">grad_vals_td0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;gradient norm (td0)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">grad_vals_tdlambda</span><span class="p">)</span> <span class="p">:],</span>
    <span class="n">grad_vals_tdlambda</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;gradient norm (td(lambda))&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;grad norm&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">traj_lengths</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj_lengths_td0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;episode length (td0)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj_lengths_tdlambda</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;episode length (td(lambda))&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;batches&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;episode length (training)&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_coding_dqn_007.png" srcset="../_images/sphx_glr_coding_dqn_007.png" alt="loss, value, grad norm, episode length (training)" class = "sphx-glr-single-img"/><p>Finally, we generate a new video to check what the algorithm has learnt.
If all goes well, the duration should be significantly longer than with the
initial, random rollout.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dummy_env</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">CatTensors</span><span class="p">([</span><span class="s2">&quot;pixels&quot;</span><span class="p">],</span> <span class="s2">&quot;pixels_save&quot;</span><span class="p">,</span> <span class="n">del_keys</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="n">eval_rollout</span> <span class="o">=</span> <span class="n">dummy_env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">actor</span><span class="p">,</span> <span class="n">auto_reset</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="n">eval_rollout</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        action: Tensor(shape=torch.Size([10, 2]), device=cpu, dtype=torch.int64, is_shared=False),
        action_value: Tensor(shape=torch.Size([10, 2]), device=cpu, dtype=torch.float32, is_shared=False),
        chosen_action_value: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),
        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),
        next: TensorDict(
            fields={
                pixels: Tensor(shape=torch.Size([10, 4, 64, 64]), device=cpu, dtype=torch.float32, is_shared=False)},
            batch_size=torch.Size([10]),
            device=cpu,
            is_shared=False),
        pixels: Tensor(shape=torch.Size([10, 4, 64, 64]), device=cpu, dtype=torch.float32, is_shared=False),
        pixels_save: Tensor(shape=torch.Size([10, 400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False),
        reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([10]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># imageio.mimwrite(&#39;cartpole.mp4&#39;, eval_rollout[&quot;pixels_save&quot;].numpy(), fps=30);</span>
<span class="c1"># Video(&#39;cartpole.mp4&#39;, width=480, height=360) #the width and height option as additional thing new in Ipython 7.6.1</span>
</pre></div>
</div>
</section>
</section>
<section id="conclusion-and-possible-improvements">
<h2>Conclusion and possible improvements<a class="headerlink" href="#conclusion-and-possible-improvements" title="Permalink to this heading">¶</a></h2>
<p>We have seen that using TD(lambda) greatly improved the performance of our
algorithm. Other possible improvements could include:</p>
<ul>
<li><p>Using the Multi-Step post-processing. Multi-step will project an action
to the nth following step, and create a discounted sum of the rewards in
between. This trick can make the algorithm noticebly less myopic. To use
this, simply create the collector with</p>
<blockquote>
<div><p>from torchrl.data.postprocs.postprocs import MultiStep
collector = CollectorClass(…, postproc=MultiStep(gamma, n))</p>
</div></blockquote>
<p>where <code class="docutils literal notranslate"><span class="pre">n</span></code> is the number of looking-forward steps. Pay attention to the
fact that the <code class="docutils literal notranslate"><span class="pre">gamma</span></code> factor has to be corrected by the number of
steps till the next observation when being passed to
<code class="docutils literal notranslate"><span class="pre">vec_td_lambda_advantage_estimate</span></code>:</p>
<blockquote>
<div><p>gamma = gamma ** tensordict[“steps_to_next_obs”]</p>
</div></blockquote>
</li>
<li><p>A prioritized replay buffer could also be used. This will give a
higher priority to samples that have the worst value accuracy.</p></li>
<li><p>A distributional loss (see <code class="docutils literal notranslate"><span class="pre">torchrl.objectives.DistributionalDQNLoss</span></code>
for more information).</p></li>
<li><p>More fancy exploration techniques, such as NoisyLinear layers and such
(check <code class="docutils literal notranslate"><span class="pre">torchrl.modules.NoisyLinear</span></code>, which is fully compatible with the
<code class="docutils literal notranslate"><span class="pre">MLP</span></code> class used in our Dueling DQN).</p></li>
</ul>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 1 minutes  47.181 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-coding-dqn-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/be66e8850a06844c91f6264538ad69e8/coding_dqn.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">coding_dqn.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/25730743bad2ad4374b1a37c2e8d077a/coding_dqn.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">coding_dqn.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../reference/index.html" class="btn btn-neutral float-right" title="API Reference" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="coding_ddpg.html" class="btn btn-neutral" title="Coding DDPG using TorchRL" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Coding a pixel-based DQN using TorchRL</a><ul>
<li><a class="reference internal" href="#hyperparameters">Hyperparameters</a></li>
<li><a class="reference internal" href="#building-the-environment">Building the environment</a></li>
<li><a class="reference internal" href="#the-problem">The problem</a></li>
<li><a class="reference internal" href="#building-the-model-deep-q-network">Building the model (Deep Q-network)</a></li>
<li><a class="reference internal" href="#regular-dqn">Regular DQN</a><ul>
<li><a class="reference internal" href="#training-loop">Training loop</a></li>
</ul>
</li>
<li><a class="reference internal" href="#td-lambda">TD-lambda</a><ul>
<li><a class="reference internal" href="#id1">Training loop</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conclusion-and-possible-improvements">Conclusion and possible improvements</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/sphinx_highlight.js"></script>
         <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>

        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>